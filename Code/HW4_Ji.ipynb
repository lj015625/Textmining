{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIA 6304 Text Mining, Fall 2017\n",
    "## Assignment 3\n",
    "### Stuent:  Leonardo Ji\n",
    "### 9/29/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T1.  Read in or create a data frame with at least one column of text to be analyzed.  This could be the text you used previously or new text. Choose a prediction you would like to make with these data and create the appropriate feature space. Identify the labels you will be trying to predict and proceed to create a train-test split. Using default model parameters, fit 3 classifiers (decision tree, naïve bayes, logistic regression, or knn) to your dataset and subsequently generate predictions (just like we did in class). Feel free to set a random state variable where appropriate to facilitate replication.  Assess the performance of the models using any of the measures (confusion matrices, precision, recall, f1-score, and accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SNAP](https://snap.stanford.edu/images/snap_logo.png \"Stanford Network Analysis Project\")\n",
    "I want to use a Amazon review data from [SNAP](https://snap.stanford.edu/data/web-Amazon.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import gzip\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', 150) #important for getting all the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10261\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2IBPI20UZIR0U</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>cassandra tu \"Yeah, well, that's just like, u...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Not much to write about here, but it does exactly what it's supposed to. filters out the pop sounds. now my recordings are much more crisp. it is ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good</td>\n",
       "      <td>1393545600</td>\n",
       "      <td>02 28, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A14VAT5EAX3D9S</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Jake</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>The product does exactly as it should and is quite affordable.I did not realized it was double screened until it arrived, so it was even better th...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jake</td>\n",
       "      <td>1363392000</td>\n",
       "      <td>03 16, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A195EZSQDW3E21</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Rick Bennette \"Rick Bennette\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>The primary job of this device is to block the breath that would otherwise produce a popping sound, while allowing your voice to pass through with...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It Does The Job Well</td>\n",
       "      <td>1377648000</td>\n",
       "      <td>08 28, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2C00NNG1ZQQG2</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>RustyBill \"Sunday Rocker\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Nice windscreen protects my MXL mic and prevents pops. Only thing is that the gooseneck is only marginally able to hold the screen in position and...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>GOOD WINDSCREEN FOR THE MONEY</td>\n",
       "      <td>1392336000</td>\n",
       "      <td>02 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A94QU4C90B1AX</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>SEAN MASLANKA</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This pop filter is great. It looks and performs like a studio filter. If you're recording vocals this will eliminate the pops that gets recorded w...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No more pops when I record my vocals.</td>\n",
       "      <td>1392940800</td>\n",
       "      <td>02 21, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A2IBPI20UZIR0U  1384719342   \n",
       "1  A14VAT5EAX3D9S  1384719342   \n",
       "2  A195EZSQDW3E21  1384719342   \n",
       "3  A2C00NNG1ZQQG2  1384719342   \n",
       "4   A94QU4C90B1AX  1384719342   \n",
       "\n",
       "                                       reviewerName   helpful  \\\n",
       "0  cassandra tu \"Yeah, well, that's just like, u...    [0, 0]   \n",
       "1                                              Jake  [13, 14]   \n",
       "2                     Rick Bennette \"Rick Bennette\"    [1, 1]   \n",
       "3                         RustyBill \"Sunday Rocker\"    [0, 0]   \n",
       "4                                     SEAN MASLANKA    [0, 0]   \n",
       "\n",
       "                                                                                                                                              reviewText  \\\n",
       "0  Not much to write about here, but it does exactly what it's supposed to. filters out the pop sounds. now my recordings are much more crisp. it is ...   \n",
       "1  The product does exactly as it should and is quite affordable.I did not realized it was double screened until it arrived, so it was even better th...   \n",
       "2  The primary job of this device is to block the breath that would otherwise produce a popping sound, while allowing your voice to pass through with...   \n",
       "3  Nice windscreen protects my MXL mic and prevents pops. Only thing is that the gooseneck is only marginally able to hold the screen in position and...   \n",
       "4  This pop filter is great. It looks and performs like a studio filter. If you're recording vocals this will eliminate the pops that gets recorded w...   \n",
       "\n",
       "   overall                                summary  unixReviewTime   reviewTime  \n",
       "0      5.0                                   good      1393545600  02 28, 2014  \n",
       "1      5.0                                   Jake      1363392000  03 16, 2013  \n",
       "2      5.0                   It Does The Job Well      1377648000  08 28, 2013  \n",
       "3      5.0          GOOD WINDSCREEN FOR THE MONEY      1392336000  02 14, 2014  \n",
       "4      5.0  No more pops when I record my vocals.      1392940800  02 21, 2014  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "amazonReview = getDF('reviews_Musical_Instruments_5.json.gz')\n",
    "print(len(amazonReview))\n",
    "amazonReview.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x181d60b8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAECCAYAAAAVYxsVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmDbqswAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181d6278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What does our target variable look like?\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get a feel for the distribution\n",
    "amazonReview['overall'].value_counts().plot(kind='bar')\n",
    "#badReview = amazonReview[(amazonReview['overall'] == 1)]\n",
    "#goodReview = amazonReview[(amazonReview['overall'] == 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10261, 20251)\n"
     ]
    }
   ],
   "source": [
    "# quick peak at basic feature space\n",
    "dm = CountVectorizer(binary=False, stop_words = 'english') \n",
    "cv_dm = dm.fit_transform(amazonReview['reviewText'])\n",
    "print(cv_dm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 20251\n"
     ]
    }
   ],
   "source": [
    "names = dm.get_feature_names()\n",
    "print(type(names), len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>guitar</th>\n",
       "      <td>5611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>4558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>4121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>3981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>3811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>3788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound</th>\n",
       "      <td>3609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strings</th>\n",
       "      <td>3420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>3235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>2683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedal</th>\n",
       "      <td>2579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>2115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>works</th>\n",
       "      <td>1871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td>1810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>1781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count\n",
       "guitar    5611\n",
       "one       4558\n",
       "great     4121\n",
       "like      3981\n",
       "good      3811\n",
       "use       3788\n",
       "sound     3609\n",
       "strings   3420\n",
       "well      3235\n",
       "get       2683\n",
       "pedal     2579\n",
       "would     2389\n",
       "really    2243\n",
       "price     2239\n",
       "amp       2115\n",
       "little    2055\n",
       "much      2003\n",
       "works     1871\n",
       "quality   1810\n",
       "also      1781"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = np.sum(cv_dm.toarray(), axis = 0).tolist()\n",
    "print(type(count), len(count))\n",
    "count_df = pd.DataFrame(count, index = names, columns = ['count'])\n",
    "\n",
    "count_df.sort_values(['count'], ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> [[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [2 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "<class 'numpy.ndarray'> [ 5.  5.  5.  5.  5.  5.  5.  3.  5.  5.]\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "# data are X, labels are y\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = cv_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "print(type(X), X[0:10])\n",
    "\n",
    "\n",
    "y = amazonReview['overall'].values #this is an array of labels\n",
    "print(type(y), y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7182, 20251)\n",
      "(3079, 20251)\n",
      "(7182,)\n",
      "(3079,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.575511529717\n",
      "accuracy: 0.575511529717\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.23      0.14      0.17        72\n",
      "        2.0       0.00      0.00      0.00        67\n",
      "        3.0       0.13      0.11      0.12       229\n",
      "        4.0       0.25      0.21      0.23       646\n",
      "        5.0       0.71      0.78      0.74      2065\n",
      "\n",
      "avg / total       0.54      0.58      0.56      3079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier(random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_test\n",
    "clf1_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.666774926924\n",
      "accuracy: 0.666774926924\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.50      0.03      0.05        72\n",
      "        2.0       0.00      0.00      0.00        67\n",
      "        3.0       0.21      0.01      0.02       229\n",
      "        4.0       0.35      0.13      0.19       646\n",
      "        5.0       0.70      0.95      0.80      2065\n",
      "\n",
      "avg / total       0.57      0.67      0.58      3079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = MultinomialNB()\n",
    "print(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y_test\n",
    "clf2_predicted = model.predict(X_test)\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.650860669048\n",
      "accuracy: 0.650860669048\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.58      0.10      0.17        72\n",
      "        2.0       0.18      0.06      0.09        67\n",
      "        3.0       0.28      0.13      0.18       229\n",
      "        4.0       0.34      0.25      0.28       646\n",
      "        5.0       0.73      0.87      0.80      2065\n",
      "\n",
      "avg / total       0.60      0.65      0.61      3079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "model = LogisticRegression(random_state = 42)\n",
    "print(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y_test\n",
    "clf3_predicted = model.predict(X_test)\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.644365053589\n",
      "accuracy: 0.644365053589\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.05      0.01      0.02        72\n",
      "        2.0       0.04      0.01      0.02        67\n",
      "        3.0       0.10      0.03      0.04       229\n",
      "        4.0       0.24      0.04      0.06       646\n",
      "        5.0       0.68      0.95      0.79      2065\n",
      "\n",
      "avg / total       0.51      0.64      0.55      3079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loading library\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# instantiate learning model (k = 3)\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "knn1_expected = y_test\n",
    "knn1_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(knn1_expected, knn1_predicted)))\n",
    "print(metrics.classification_report(knn1_expected, knn1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q1. Write a short description of the results of these “baseline” models. Make sure your answer is no longer than four paragraphs, and should at minimum answer these questions:\n",
    "*\tWhat decisions did you make when creating your feature space? Why?  \n",
    "*\tHow do these classifiers address your question?\n",
    "*\tHow did your models perform? Are you happy with the results?  Why or why not?\n",
    "Audience: general – management or non-technical staff. NOTE: this is a GENERAL AUDIENCE RESPONSE - be VERY careful with how you mention/describe/discuss the various models.  Detailed descriptions of the classifiers is not required but any discussion of them must be NON TECHNICAL (but not fluffy).   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used 10,261 Amazon music instrument review dataset for this question.  I want to know whether the review text can predict the overall rating of the products.  I used four models. The common stop words like a, an, the... are removed. All four models predict products’ overall rating based on data generated from counting single word term in the reviews.  \n",
    "Four models produced accuracies around 60%.  The accuracies are lower than I expected.\n",
    "All four models are better at predict overall rating of 1/1 or 5/5.  The middle overall rating are harder to predict because the words people use for great product and poor products are very unique. The user usually use positive words to describe product rated 5/5, and negative words to describe products rated 1/5. The average rating review likely do not stand out like those rated 1/1 or 5/5.  \n",
    "\n",
    "The first model has overall accuracy of 57.5%, the second model has overall accuracy of 66.7%, the third model has overall accuracy of 65.1%, and the fourth model has overall accuracy of 64.4%.  The second and third models are much better than the other two models because they are better at predicting both very good rating (5/5) and very bad rating (1/1).  In the following section I will try to improve these base models.  I will focus on improve very bad rating where user ranked the product 1/1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T2. Using a variety of parameter settings (for classifiers or vectorizers), try to improve on the performance of the baseline models.  At least 6 separate predictions should be run and the results reported in a table.  You can use any combination of parameters and classifiers; you do not need to use all classifiers. Make sure at least one example uses a preprocessing option (stemming, lemmatization, custom dictionary, custom stopwords, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "# create a custom stopwords list - I choose to start with the nltk list\n",
    "nltk_stopwords = stopwords.words(\"english\")\n",
    "print(len(nltk_stopwords))\n",
    "new_nltk_stopwords = set(nltk_stopwords)\n",
    "new_nltk_stopwords.update(set(['first', 'one', 'two', 'last', 'another', 'could', 'would', 'need']))\n",
    "print(len(new_nltk_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n",
      "319\n"
     ]
    }
   ],
   "source": [
    "skl_stopwords = text.ENGLISH_STOP_WORDS\n",
    "new_skl_stopwords = set(skl_stopwords)\n",
    "print(len(new_skl_stopwords))\n",
    "new_skl_stopwords.update(set(['need']))\n",
    "print(len(new_skl_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing to replace words\n",
    "import re\n",
    "my_dict = {'guitars':'guitar','picks':'pick', 'strings':'string', 'bought':'buy',\n",
    "             'years': 'year', 'works':'work', 'schools':'school', 'using':'use',\n",
    "            'sounds':'sound', 'makes':'make', 'made':'make', 'pedels':'pedel', 'playing':'play', 'tried':'try'}\n",
    "\n",
    "\n",
    "def multiple_replace(dict, text): \n",
    "\n",
    "  \"\"\" Replace in 'text' all occurences of any key in the given\n",
    "  dictionary by its corresponding value.  Returns the new tring.\"\"\" \n",
    "  text = str(text).lower()\n",
    "\n",
    "  # Create a regular expression  from the dictionary keys\n",
    "  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n",
    "\n",
    "  # For each match, look-up corresponding value in dictionary\n",
    "  return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text)\n",
    "\n",
    "amazonReview['cleantext'] = amazonReview.reviewText.apply(lambda x: multiple_replace(my_dict, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer() #define method (http://www.nltk.org/api/nltk.stem.html#nltk.stem.porter.PorterStemmer)\n",
    "amazonReview['StemReviewText'] = [ps.stem(word) for word in amazonReview['reviewText']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use count vectorizer 1: lowercase=True, stop_words=new_skl_stopwords,binary=False,max_df=0.95, min_df=0.05,ngram_range = (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv1 = CountVectorizer(lowercase=True, \n",
    "                     stop_words=new_skl_stopwords,\n",
    "                     binary=False,\n",
    "                     max_df=0.95, \n",
    "                     min_df=0.05,\n",
    "                     ngram_range = (1,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10261, 88)\n",
      "<class 'list'> 88\n"
     ]
    }
   ],
   "source": [
    "cv_dm = cv1.fit_transform(amazonReview['cleantext'])\n",
    "print(cv_dm.shape)\n",
    "\n",
    "names = cv1.get_feature_names()\n",
    "print(type(names), len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>guitar</th>\n",
       "      <td>6846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>5221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>string</th>\n",
       "      <td>4721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound</th>\n",
       "      <td>4704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>4121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>3981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>3811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>3757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>3128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>2875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy</th>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedal</th>\n",
       "      <td>2579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play</th>\n",
       "      <td>2554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pick</th>\n",
       "      <td>2287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>2115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ve</th>\n",
       "      <td>2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don</th>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "guitar   6846\n",
       "use      5221\n",
       "string   4721\n",
       "sound    4704\n",
       "great    4121\n",
       "like     3981\n",
       "good     3811\n",
       "just     3757\n",
       "work     3128\n",
       "make     2875\n",
       "buy      2648\n",
       "pedal    2579\n",
       "play     2554\n",
       "pick     2287\n",
       "really   2243\n",
       "price    2239\n",
       "amp      2115\n",
       "ve       2079\n",
       "little   2055\n",
       "don      1972"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = np.sum(cv_dm.toarray(), axis = 0).tolist()\n",
    "print(type(count), len(count))\n",
    "count_df = pd.DataFrame(count, index = names, columns = ['count'])\n",
    "\n",
    "count_df.sort_values(['count'], ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "# data are X, labels are y\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = cv_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "#print(type(X), X[0:10])\n",
    "\n",
    "\n",
    "y = amazonReview['overall'].values #this is an array of labels\n",
    "#print(type(y), y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7182, 88)\n",
      "(3079, 88)\n",
      "(7182,)\n",
      "(3079,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.526144852225\n",
      "accuracy: 0.526144852225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.04      0.04      0.04        72\n",
      "        2.0       0.03      0.03      0.03        67\n",
      "        3.0       0.12      0.12      0.12       229\n",
      "        4.0       0.24      0.27      0.26       646\n",
      "        5.0       0.71      0.68      0.70      2065\n",
      "\n",
      "avg / total       0.54      0.53      0.53      3079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier(random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_test\n",
    "clf1_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.653134134459\n",
      "accuracy: 0.653134134459\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.26      0.11      0.16        72\n",
      "        2.0       0.05      0.03      0.04        67\n",
      "        3.0       0.15      0.04      0.06       229\n",
      "        4.0       0.37      0.12      0.19       646\n",
      "        5.0       0.70      0.93      0.80      2065\n",
      "\n",
      "avg / total       0.57      0.65      0.58      3079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = MultinomialNB()\n",
    "print(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y_test\n",
    "clf2_predicted = model.predict(X_test)\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.669697953881\n",
      "accuracy: 0.669697953881\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.75      0.04      0.08        72\n",
      "        2.0       0.20      0.01      0.03        67\n",
      "        3.0       0.12      0.01      0.02       229\n",
      "        4.0       0.40      0.06      0.10       646\n",
      "        5.0       0.68      0.98      0.80      2065\n",
      "\n",
      "avg / total       0.57      0.67      0.56      3079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "model = LogisticRegression(random_state = 42)\n",
    "print(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y_test\n",
    "clf3_predicted = model.predict(X_test)\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use count vectorizer 2: lowercase=True, stop_words=new_skl_stopwords,binary=False,max_df=0.95, min_df=0.05,ngram_range = (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2 = CountVectorizer(lowercase=True, \n",
    "                     stop_words=new_skl_stopwords,\n",
    "                     binary=False,\n",
    "                     max_df=0.95, \n",
    "                     min_df=0.05,\n",
    "                     ngram_range = (1,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10261, 98)\n",
      "<class 'list'> 98\n"
     ]
    }
   ],
   "source": [
    "cv2_dm = cv2.fit_transform(amazonReview['StemReviewText'])\n",
    "\n",
    "# print matrix shape(s)\n",
    "print(cv2_dm.shape)\n",
    "names = cv2.get_feature_names()\n",
    "print(type(names), len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 98\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>guitar</th>\n",
       "      <td>5617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>4121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>3981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>3811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>3783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>3757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound</th>\n",
       "      <td>3610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strings</th>\n",
       "      <td>3408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedal</th>\n",
       "      <td>2575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>2229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>2115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ve</th>\n",
       "      <td>2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don</th>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>works</th>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td>1805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>used</th>\n",
       "      <td>1762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nice</th>\n",
       "      <td>1707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better</th>\n",
       "      <td>1688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count\n",
       "guitar    5617\n",
       "great     4121\n",
       "like      3981\n",
       "good      3811\n",
       "use       3783\n",
       "just      3757\n",
       "sound     3610\n",
       "strings   3408\n",
       "pedal     2575\n",
       "really    2243\n",
       "price     2229\n",
       "amp       2115\n",
       "ve        2079\n",
       "little    2055\n",
       "don       1975\n",
       "works     1867\n",
       "quality   1805\n",
       "used      1762\n",
       "nice      1707\n",
       "better    1688"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = np.sum(cv2_dm.toarray(), axis = 0).tolist()\n",
    "print(type(count), len(count))\n",
    "count_df = pd.DataFrame(count, index = names, columns = ['count'])\n",
    "\n",
    "count_df.sort_values(['count'], ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "# data are X, labels are y\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = cv2_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "#print(type(X), X[0:10])\n",
    "\n",
    "y = amazonReview['overall'].values #this is an array of labels\n",
    "#print(type(y), y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7182, 98)\n",
      "(3079, 98)\n",
      "(7182,)\n",
      "(3079,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53329002923\n",
      "accuracy: 0.53329002923\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.04      0.04      0.04        72\n",
      "        2.0       0.01      0.01      0.01        67\n",
      "        3.0       0.10      0.12      0.11       229\n",
      "        4.0       0.25      0.25      0.25       646\n",
      "        5.0       0.72      0.70      0.71      2065\n",
      "\n",
      "avg / total       0.54      0.53      0.54      3079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier(random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_test\n",
    "clf1_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.646963299773\n",
      "accuracy: 0.646963299773\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.19      0.10      0.13        72\n",
      "        2.0       0.03      0.01      0.02        67\n",
      "        3.0       0.11      0.03      0.05       229\n",
      "        4.0       0.35      0.12      0.18       646\n",
      "        5.0       0.70      0.92      0.79      2065\n",
      "\n",
      "avg / total       0.56      0.65      0.58      3079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = MultinomialNB()\n",
    "print(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y_test\n",
    "clf2_predicted = model.predict(X_test)\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.672620980838\n",
      "accuracy: 0.672620980838\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.60      0.04      0.08        72\n",
      "        2.0       0.40      0.03      0.06        67\n",
      "        3.0       0.17      0.01      0.02       229\n",
      "        4.0       0.44      0.07      0.11       646\n",
      "        5.0       0.68      0.98      0.80      2065\n",
      "\n",
      "avg / total       0.59      0.67      0.57      3079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "model = LogisticRegression(random_state = 42)\n",
    "print(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y_test\n",
    "clf3_predicted = model.predict(X_test)\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use tfidf vectorizer: lowercase = True, stop_words= new_nltk_stopwords, max_df=0.95, min_df=0.05, ngram_range = (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf1 = TfidfVectorizer(lowercase = True, \n",
    "                        stop_words= new_nltk_stopwords, \n",
    "                        max_df=0.95, \n",
    "                        min_df=0.05,\n",
    "                        ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10261, 108)\n",
      "<class 'list'> 108\n"
     ]
    }
   ],
   "source": [
    "tfidf_dm = tfidf1.fit_transform(amazonReview['cleantext'])\n",
    "\n",
    "# print matrix shape(s)\n",
    "print(tfidf_dm.shape)\n",
    "names = tfidf1.get_feature_names()\n",
    "print(type(names), len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 108\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>guitar</th>\n",
       "      <td>921.348728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>string</th>\n",
       "      <td>757.355210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>741.822023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>727.593655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>661.405896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound</th>\n",
       "      <td>658.414304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>601.677799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>588.873463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>560.198404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy</th>\n",
       "      <td>504.929865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pick</th>\n",
       "      <td>493.954955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>471.305673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>456.045952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedal</th>\n",
       "      <td>435.874534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>431.270179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>408.523931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play</th>\n",
       "      <td>404.441493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td>390.630735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>382.410045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nice</th>\n",
       "      <td>379.834002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "guitar   921.348728\n",
       "string   757.355210\n",
       "use      741.822023\n",
       "great    727.593655\n",
       "good     661.405896\n",
       "sound    658.414304\n",
       "work     601.677799\n",
       "like     588.873463\n",
       "well     560.198404\n",
       "buy      504.929865\n",
       "pick     493.954955\n",
       "make     471.305673\n",
       "price    456.045952\n",
       "pedal    435.874534\n",
       "get      431.270179\n",
       "really   408.523931\n",
       "play     404.441493\n",
       "quality  390.630735\n",
       "little   382.410045\n",
       "nice     379.834002"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = np.sum(tfidf_dm.toarray(), axis = 0).tolist()\n",
    "print(type(count), len(count))\n",
    "count_df = pd.DataFrame(count, index = names, columns = ['count'])\n",
    "\n",
    "count_df.sort_values(['count'], ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "# data are X, labels are y\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = tfidf_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "#print(type(X), X[0:10])\n",
    "\n",
    "y = amazonReview['overall'].values #this is an array of labels\n",
    "#print(type(y), y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7182, 108)\n",
      "(3079, 108)\n",
      "(7182,)\n",
      "(3079,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.539460863917\n",
      "accuracy: 0.539460863917\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.09      0.07      0.08        72\n",
      "        2.0       0.03      0.03      0.03        67\n",
      "        3.0       0.09      0.09      0.09       229\n",
      "        4.0       0.25      0.23      0.24       646\n",
      "        5.0       0.70      0.72      0.71      2065\n",
      "\n",
      "avg / total       0.53      0.54      0.53      3079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier(random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_test\n",
    "clf1_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.6706722962\n",
      "accuracy: 0.6706722962\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.00      0.00      0.00        72\n",
      "        2.0       0.00      0.00      0.00        67\n",
      "        3.0       0.00      0.00      0.00       229\n",
      "        4.0       0.00      0.00      0.00       646\n",
      "        5.0       0.67      1.00      0.80      2065\n",
      "\n",
      "avg / total       0.45      0.67      0.54      3079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = MultinomialNB()\n",
    "print(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y_test\n",
    "clf2_predicted = model.predict(X_test)\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.673270542384\n",
      "accuracy: 0.673270542384\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.00      0.00      0.00        72\n",
      "        2.0       0.00      0.00      0.00        67\n",
      "        3.0       0.50      0.00      0.01       229\n",
      "        4.0       0.40      0.09      0.14       646\n",
      "        5.0       0.69      0.98      0.81      2065\n",
      "\n",
      "avg / total       0.58      0.67      0.57      3079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "model = LogisticRegression(random_state = 42)\n",
    "print(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y_test\n",
    "clf3_predicted = model.predict(X_test)\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use PCA to reduce feature spaces on count vectorizer 3 lowercase=True, stop_words=new_skl_stopwords,binary=False,max_df=0.95,min_df=0.001,ngram_range = (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv3 = CountVectorizer(lowercase=True, \n",
    "                     stop_words=new_skl_stopwords,\n",
    "                     binary=False,\n",
    "                     max_df=0.95,\n",
    "                     min_df=0.001, #prevent memory error have to set a min_df\n",
    "                     ngram_range = (1,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10261, 5883)\n",
      "<class 'list'> 5883\n"
     ]
    }
   ],
   "source": [
    "cv3_dm = cv3.fit_transform(amazonReview['cleantext'])\n",
    "\n",
    "# print matrix shape(s)\n",
    "print(cv3_dm.shape)\n",
    "names = cv3.get_feature_names()\n",
    "print(type(names), len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10261, 5883)\n",
      "PCA Total Variance Explained: 0.828651554237\n"
     ]
    }
   ],
   "source": [
    "# Is this what we need to get better predictions for our news articles?\n",
    "# First question:  How many components?\n",
    "\n",
    "# Our original feature space was pretty big\n",
    "print(cv3_dm.shape)\n",
    "\n",
    "from sklearn.decomposition import PCA, RandomizedPCA\n",
    "\n",
    "# we want something that is smaller than 5883 \n",
    "# let's start with 800 - that's about how big the second round space was\n",
    "# maybe we've kept more info for the same number of features\n",
    "\n",
    "\n",
    "pca = PCA(n_components=800)\n",
    "X_pca = pca.fit_transform(cv3_dm.toarray())\n",
    "\n",
    "print( 'PCA Total Variance Explained: ' + str(sum(pca.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.506658005846\n",
      "accuracy: 0.506658005846\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.03      0.03      0.03        72\n",
      "        2.0       0.04      0.06      0.05        67\n",
      "        3.0       0.08      0.10      0.08       229\n",
      "        4.0       0.26      0.26      0.26       646\n",
      "        5.0       0.69      0.66      0.67      2065\n",
      "\n",
      "avg / total       0.52      0.51      0.52      3079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#set up our test and training vectors with the PCA'd vector space\n",
    "X = X_pca  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "y = amazonReview['overall'].values #this is an array of labels\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #random_state is set seed\n",
    "\n",
    "\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier(random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_test\n",
    "clf1_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.666450146151\n",
      "accuracy: 0.666450146151\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.39      0.10      0.16        72\n",
      "        2.0       0.18      0.09      0.12        67\n",
      "        3.0       0.25      0.14      0.18       229\n",
      "        4.0       0.39      0.22      0.28       646\n",
      "        5.0       0.73      0.90      0.81      2065\n",
      "\n",
      "avg / total       0.61      0.67      0.62      3079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a logistic regression model to the data\n",
    "model = LogisticRegression(random_state = 42)\n",
    "print(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y_test\n",
    "clf3_predicted = model.predict(X_test)\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use TfidfVectorizer 2: lowercase = True, binary=False, stop_words = new_nltk_stopwords,max_df=0.95, min_df=0.001, ngram_range = (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf2 = TfidfVectorizer(lowercase = True, \n",
    "                          binary=False, \n",
    "                          stop_words = new_nltk_stopwords,\n",
    "                          max_df=0.95,\n",
    "                          min_df=0.001,  #prevent memory error have to set a min_df\n",
    "                          use_idf = False,\n",
    "                          ngram_range = (1,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10261, 6238)\n",
      "<class 'list'> 6238\n"
     ]
    }
   ],
   "source": [
    "tfidf2_dm = tfidf2.fit_transform(amazonReview['cleantext'])\n",
    "\n",
    "# print matrix shape(s)\n",
    "print(tfidf2_dm.shape)\n",
    "names = tfidf2.get_feature_names()\n",
    "print(type(names), len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "# data are X, labels are y\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = tfidf2_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "#print(type(X), X[0:10])\n",
    "\n",
    "y = amazonReview['overall'].values #this is an array of labels\n",
    "#print(type(y), y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use cosine similarity \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "X = cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7182, 10261)\n",
      "(3079, 10261)\n",
      "(7182,)\n",
      "(3079,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.539460863917\n",
      "accuracy: 0.539460863917\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.02      0.03      0.02        72\n",
      "        2.0       0.06      0.13      0.09        67\n",
      "        3.0       0.11      0.12      0.11       229\n",
      "        4.0       0.26      0.14      0.18       646\n",
      "        5.0       0.69      0.74      0.71      2065\n",
      "\n",
      "avg / total       0.53      0.54      0.53      3079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loading library\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# instantiate learning model (k = 3)\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "knn1_expected = y_test\n",
    "knn1_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(knn1_expected, knn1_predicted)))\n",
    "print(metrics.classification_report(knn1_expected, knn1_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7182, 6238)\n",
      "(3079, 6238)\n",
      "(7182,)\n",
      "(3079,)\n"
     ]
    }
   ],
   "source": [
    "X = tfidf2_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666450146151\n",
      "accuracy: 0.666450146151\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.00      0.00      0.00        72\n",
      "        2.0       0.17      0.01      0.03        67\n",
      "        3.0       0.12      0.01      0.02       229\n",
      "        4.0       0.25      0.00      0.00       646\n",
      "        5.0       0.67      0.99      0.80      2065\n",
      "\n",
      "avg / total       0.52      0.67      0.54      3079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instantiate learning model (k = 3)\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "knn1_expected = y_test\n",
    "knn1_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(knn1_expected, knn1_predicted)))\n",
    "print(metrics.classification_report(knn1_expected, knn1_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# creating odd list of K for KNN\n",
    "myList = list(range(1,35))\n",
    "\n",
    "# subsetting just the odd ones\n",
    "neighbors = list(filter(lambda x: x % 2 != 0, myList))\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "#takes some time, get a soda...\n",
    "# perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is 29\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl83GW5///XO2ubpeuEtnShSVsolaWUUhBbF0QoopRN\nEFnFA9YjCn4VQf1+ReHnArgf0IpQBeUcKEc4otaDWFlaRGiLZSndQhdo6ZKULkmXNMv1++Nzp52G\nSTJNMplM5no+HvOYmfuz5JqB5sr9ue/PdcvMcM455zoqJ90BOOecy2yeSJxzznWKJxLnnHOd4onE\nOedcp3gicc451ymeSJxzznWKJxLnnHOd4onEOedcp3gicc451yl56Q6gO8RiMRs9enS6w3DOuYyy\nePHiajMra2+/rEgko0ePZtGiRekOwznnMoqkdcns55e2nHPOdYonEuecc53iicQ551yneCJxzjnX\nKZ5InHPOdYonEuecc53iicQ551yneCJpw9+Xb+bnT1emOwznnOvRPJG04bnKrfxs3iqamnxde+ec\na40nkjZUlBWzt76JTTv3pjsU55zrsTyRtKE8VgzA6qpdaY7EOed6Lk8kbaiIlQCwpro2zZE451zP\n5YmkDUP6FVJUkMvqau+ROOdca1KaSCRNl7RCUqWkmxNsnyHpFUlLJC2SNDW095H0oqSXJS2V9O0W\nx31B0vKw7Y4Uxk95rNgvbTnnXBtSVkZeUi5wN/ARYD2wUNLjZvZ63G7zgMfNzCQdB8wBxgN1wGlm\nVispH1gg6S9m9k9JHwJmAMebWZ2kw1L1GSAaJ3ll/Y5U/gjnnMtoqeyRTAEqzWy1me0DHiJKAPuZ\nWa2ZNc+tLQYstJuZNQ9M5IdH836fA75vZnVh3y0p/AxUxIpZv203dQ2NqfwxzjmXsVKZSIYDb8W9\nXx/aDiLpPEnLgT8DV8e150paAmwBnjSzF8KmI4Fpkl6Q9IykkxL9cEnXhstli6qqqjr8ISrKSmgy\neOud3R0+h3PO9WZpH2w3s8fMbDxwLnBbXHujmU0ERgBTJB0TNuUBg4BTgBuBOZKU4Lz3mNlkM5tc\nVtbuSpGtap4C/IaPkzjnXEKpTCQbgJFx70eEtoTM7FmgQlKsRft24ClgemhaDzwaLn+9CDQBBx3T\nlcrLokSyxmduOedcQqlMJAuBcZLKJRUAnwQej99B0tjm3oSkSUAhsFVSmaQBob0v0YD98nDY/wAf\nCtuOBAqA6lR9iH598omVFLLGeyTOOZdQymZtmVmDpOuAJ4BcYLaZLZU0M2yfBVwAXCGpHtgDXBxm\ncA0D7g8zv3KAOWb2p3Dq2cBsSa8B+4Ar4wbsU6IiVsxqvynROecSSlkiATCzucDcFm2z4l7fDtye\n4LhXgBNaOec+4LKujbRt5bFi5i3f3J0/0jnnMkbaB9szQXlZMdW1+9ixpz7doTjnXI/jiSQJFWHm\n1lofcHfOuXfxRJKEijBzy8dJnHPu3TyRJGHkoCJyhM/ccs65BDyRJKEwL5eRg4q8CrBzziXgiSRJ\nXgXYOecS80SSpPJYMWuqd5HiW1accy7jeCJJUkWsmD31jWzeWZfuUJxzrkfxRJKkirJo2d3VVT5z\nyznn4nkiSVJzFWAfcHfOuYN5IknS0H596JOf41WAnXOuBU8kScrJEeWxEk8kzjnXgieSQ1ARK/Yx\nEueca8ETySEojxXz1rY97GtoSncozjnXY3giOQTlsWIam4y3tvn67c451yyliUTSdEkrJFVKujnB\n9hmSXpG0RNIiSVNDex9JL0p6WdJSSd9OcOyXJVnLpXlTaX/xRr/D3Tnn9ktZIgmrG94NnAVMAC6R\nNKHFbvOA481sInA1cG9orwNOM7PjgYnAdEmnxJ17JHAG8Gaq4k+keQrwGq8C7Jxz+6WyRzIFqDSz\n1WFVw4eAGfE7mFlt3DK5xYCFdjOz5t/W+eERX5vkx8BXW7Sl3ICiAgYVF/jMLeeci5PKRDIceCvu\n/frQdhBJ50laDvyZqFfS3J4raQmwBXjSzF4I7TOADWb2cgpjb1WFF290zrmDpH2w3cweM7PxwLnA\nbXHtjeGS1whgiqRjJBUBXwe+2d55JV0bxl0WVVVVdVm85bFiv7vdOefipDKRbABGxr0fEdoSMrNn\ngYqWg+dmth14CpgOjAHKgZclrQ3nfEnS0ATnu8fMJpvZ5LKyss5+lv3Ky4qpqqmjZq+v3+6cc5Da\nRLIQGCepXFIB8Eng8fgdJI2VpPB6ElAIbJVUJmlAaO8LfARYbmavmtlhZjbazEYTXS6bZGabUvg5\nDlIRi4o3rq32KcDOOQeQl6oTm1mDpOuAJ4BcYLaZLZU0M2yfBVwAXCGpHtgDXGxmJmkYcH+Y+ZUD\nzDGzP6Uq1kMRv377sSP6pzka55xLv5QlEgAzmwvMbdE2K+717cDtCY57BTghifOP7nyUh2bUoCIk\nv5fEOeeapX2wPdP0yc9l+IC+PgXYOecCTyQdUFHmVYCdc66ZJ5IOaK4C7Ou3O+ecJ5IOKY8Vs2tf\nI1U1vn67c855IumAAzO3/PKWc855IumA/eu3+8wt55zzRNIRh/fvS0FejlcBds452kkkoXDiD7or\nmEyRkyPKBxf7zC3nnKOdRGJmjcDUboolo1SUeRVg55yD5O5s/5ekx4FHgP2/Oc3s0ZRFlQHKY8U8\n+fpm6hubyM/1K4TOueyVTCLpA2wFTotrMyDrE0lDk7F+2579g+/OOZeN2k0kZvbp7ggk01SURVWA\n11TXeiJxzmW1dq/JSBoh6TFJW8Lj95JGdEdwPVmFTwF2zjkguem/vyZaR+Tw8PhjaMtqA4sLGFCU\n7zclOueyXjKJpMzMfm1mDeHxG6DrlhzMYOWxYtZ4j8Q5l+WSSSRbJV0W7inJlXQZ0eB71quIlbDa\nb0p0zmW5ZBLJ1cBFwCZgI3AhkNQAvKTpklZIqpR0c4LtMyS9ImmJpEWSpob2PpJelPSypKWSvh13\nzJ2SlofjHmtekjcdKsqK2byzjl11DekKwTnn0q7dO9uB883sHDMrC+uln2tmb7Z34nDs3cBZwATg\nEkkTWuw2DzjezCYSJax7Q3sdcJqZHQ9MBKZLOiVsexI4xsyOA1YCX0vqk6ZA82wtv8PdOZfNkrmz\n/ZIOnnsKUGlmq81sH/AQMKPF+WvtwKIexUT3p2CR5mtG+eHRvO2vZtbcBfgnkLYZZM1VgD2ROOey\nWTKXtp6TdJekaZImNT+SOG448Fbc+/Wh7SCSzpO0HPgzUa+kuT1X0hJgC/Ckmb2Q4GdcDfwliVhS\nYvRgnwLsnHPJ3Nk+MTzfGtdmHHyne4eZ2WPAY5LeD9wGnB7aG4GJYQzkMUnHmNlrzcdJ+gbQADyY\n6LySrgWuBRg1alRXhPouB9Zv9wF351z2ajORSMoBfmFmczpw7g3AyLj3I0JbQmb2rKQKSTEzq45r\n3y7pKWA68FqI6yrgY8CH4y6NtTzfPcA9AJMnT07ZmrjlMa8C7JzLbu2NkTQBX+3guRcC4ySVSyoA\nPkl0Y+N+ksZKUng9CSgkmm5c1jwbS1Jf4CPA8vB+eojpHDPb3cHYukxzFWBfv905l62SubT1N0lf\nAR7m4Oq/77R1kJk1SLoOeALIBWab2VJJM8P2WcAFwBWS6oE9wMVmZpKGAfeHmV85wBwz+1M49V1E\nCefJkIP+aWYzk//IXas8VkxNXQPVtfsoKy1MVxjOOZc2ySSSi8Pz5+PaDKho70AzmwvMbdE2K+71\n7cDtCY57BTihlXOObT/k7hM/BdgTiXMuGyVT/be8OwLJVGPiqgBPKR+U5micc677tTpGIumrca8/\n0WLbd1MZVCY5fEBfCnJzfAqwcy5rtTXY/sm41y3vHp+eglgyUm6OOGJwkVcBds5lrbYSiVp5neh9\nVqso8ynAzrns1VYisVZeJ3qf1cpjJazbuouGxqZ0h+Kcc92urcH24yXtJOp99A2vCe/7pDyyDFIR\nK6a+0diwfQ9HDPZld51z2aXVRGJmud0ZSCYrD8UbV1fv8kTinMs6yRRtdO3w9dudc9nME0kXGFRc\nQL8+eV680TmXlTyRdAFJlJeV+Mwt51xW8kTSRcbEilnjl7acc1mo3UQi6XxJqyTtkLRTUk3cDC4X\nlMeKeXvHXnbv8/XbnXPZJZkeyR1EJdv7m1k/Mys1s36pDizTNM/cWlud9sr2zjnXrZJJJJvNbFnK\nI8lw8VWAnXMumyRTRn6RpIeB/wHqmhvN7NGURZWByvdPAfaZW8657JJMIukH7AbOiGszwBNJnKKC\nPIb17+M9Eudc1klmPZJPd/TkYVncnxKtkHivmX2/xfYZwG1AE9AA3GBmCyT1AZ4lWgkxD/hvM7sl\nHDOIaLXG0cBa4CIz29bRGLtSeazYqwA757JOMrO2Rkh6TNKW8Pi9pBFJHJcL3A2cBUwALpE0ocVu\n84DjzWwicDVwb2ivA04zs+OBicB0SaeEbTcD88xsXDj+5vY/ZveI1m+v9fXbnXNZJZnB9l8DjwOH\nh8cfQ1t7pgCVZrbazPYBDwEz4ncws1o78Fu3mFBV2CLNgw354dG83wzg/vD6fuDcJGLpFuWxEnbu\nbeCdXfvSHYpzznWbZBJJmZn92swawuM3QFkSxw0H3op7vz60HUTSeZKWA38m6pU0t+dKWgJsAZ40\nsxfCpiFmtjG83gQMSSKWblHhM7ecc1komUSyVdJl4Rd7rqTLgK1dFYCZPWZm44l6FrfFtTeGS14j\ngCmSjklwrNHK2iiSrpW0SNKiqqqqrgq3Tftnbnkicc5lkWQSydXARUR//W8ELgSSGYDfAIyMez8i\ntCVkZs8CFZJiLdq3A09xYHnfzZKGAYTnLa2c7x4zm2xmk8vKkulAdd6IgX3Jz5VXAXbOZZV2E4mZ\nrTOzc8yszMwOM7NzzezNJM69EBgnqVxSAdEa8I/H7yBprCSF15OIZmltlVQmaUBo7wt8BFgeDnsc\nuDK8vhL4QxKxdIu83BxGDSryKsDOuazS6vRfSV81szsk/QcJLh+Z2RfbOrGZNUi6DniCaPrvbDNb\nKmlm2D4LuAC4QlI9sAe42Mws9DTuDzO/coA5ZvancOrvA3MkfQZYR9Rb6jHKY14F2DmXXdq6j6S5\nLMqijp7czOYCc1u0zYp7fTtwe4LjXgFOaOWcW4EPdzSmVBtTVsyzq6pobDJyc5TucJxzLuXaWmr3\nj+HlbjN7JH6bpE+kNKoMVh4rZl9DE29v38PIQUXpDsc551IumcH2ryXZ5vCZW8657NPWGMlZwEeB\n4ZJ+FrepH1E5E5dARVkJAGuqavnAkd0zW8w559KprTGSt4nGR84BFse11wBfSmVQmSxWUkBpYZ73\nSJxzWaOtMZKXgZcl/aeZ1XdjTBktWr+92GduOeeyRjJjJKMl/bek1yWtbn6kPLIMVh4r9psSnXNZ\nI9mijb8gGhf5EPAA8LtUBpXpKmIlvL1jD3vrG9MdinPOpVwyiaSvmc0DFO5y/xZwdmrDymzlZcWY\nwdqt3itxzvV+ySSSOkk5wCpJ10k6DyhJcVwZbX8VYL+85ZzLAskkkuuBIuCLwInAZRyodeUS8HtJ\nnHPZJJmldheGl7UkV/U36xUX5jGkX6EPuDvnskIyS+0+2VyJN7wfKOmJ1IaV+cpjxV4F2DmXFZK5\ntBULa4IAYGbbgMNSF1Lv4FWAnXPZIplE0iRpVPMbSUfQyqqE7oAxZcVs213PNl+/3TnXy7U7RgJ8\nA1gg6RlAwDTg2pRG1QvED7ifWFyQ5miccy51khls/9+weuEpoekGM6tObViZrzmRrKnexYlHDExz\nNM45lzqtXtqSND48TwJGERVxfBsYFdraJWm6pBWSKiXdnGD7DEmvSFoiaZGkqaF9pKSnQlmWpZKu\njztmoqR/xh0z5dA+cvcYOaiIvBz5gLtzrtdrq0fyf4guYf0wwTYDTmvrxGGZ3LuJ1ltfDyyU9LiZ\nvR632zzg8bC87nHAHGA8UTmWL5vZS5JKgcWSngzH3gF828z+Iumj4f0Hk/is3So/rN/uU4Cdc71d\nW4nkyfD8GTPrSJHGKUBl87GSHgJmAPsTiZnF/7leTBjEN7ONwMbwukbSMmB4ONaI1kQB6E/US+qR\noinAnkicc71bW7O2mldB/O8Onns48Fbc+/Wh7SCSzpO0HPgzcHWC7aOJ1m9/ITTdANwp6S3gB7Sy\nWqOka8Olr0VVVVUd/Aid05xImpp8kptzrvdqK5FslfRXoFzS4y0fXRWAmT1mZuOBc4Hb4rdJKgF+\nTzTAvzM0fw74kpmNJFpg675WznuPmU02s8llZelZqbCirIS6hibe3rEnLT/fOee6Q1uXts4GJgG/\nJfE4SXs2ACPj3o8IbQmZ2bOSKiTFzKxaUj5REnnQzB6N2/VKovpfAI8A93Ygtm4RP3NrxMCiNEfj\nnHOp0dYKifuAf0o61cw6cm1oITBOUjlRAvkk8Kn4HSSNBd4Ig+2TgEKinpCIehrLzOxHLc77NvAB\n4GmiAf9VHYitW1SUHUgk08b5+u3Oud6p1UQi6SdmdgMwW9K7LvKb2TltndjMGiRdBzwB5AKzzWyp\npJlh+yzgAuAKSfXAHuDikFSmApcDr0paEk75dTObC1wD/FRSHrCXHnxz5GGlhRQX5PrMLedcr9bW\npa3fhucfdPTk4Rf/3BZts+Je3w7cnuC4BUR30Sc65wKicvY9XvP67V5O3jnXm7V1aWtxeH6muU3S\nQGCkmb3SDbH1CuWxEpa8tS3dYTjnXMokU0b+aUn9JA0CXgJ+JanluIVrRUWsmPXb9lDX4Ou3O+d6\np2Sq//YPU2/PBx4ws5OB01MbVu9REdZvX7d1d7pDcc65lEgmkeRJGgZcBPwpxfH0OvurAPuAu3Ou\nl0omkdxKNPOq0swWSqqgB0+57Wni7yVxzrneKJky8o8Q3fjX/H410bRdl4TSPvmUlRayusqrADvn\neqdkBtvvCIPt+ZLmSaqSdFl3BNdbePFG51xvlsylrTPCYPvHgLXAWODGVAbV21R4InHO9WJJDbaH\n57OBR8xsRwrj6ZUqyorZumsfO3bXpzsU55zrcskkkj+FMu8nAvMklRGVJnFJKo+VALDaV0t0zvVC\nyQy23yzpDmCHmTVK2kW0QJVLUvzMrRNGdWz99r31jVRuqWXl5hpWbKqhX998Zn5gDLk5CSvJOOdc\nt2k3kQSHA6dL6hPX9kAK4umVRg0qIjdHSY2TNDYZb76zmxWbooSxYvNOVmyqYe3W3TSGBbLyc0V9\no7F+226+e96xRMWSnXMuPdpNJJJuIVoTfQJRAcazgAV4IklaQV4OIwf2PeimRDOjqqaO5ZtqWLm5\nZv/zys017K1vAkCKktBRQ0o5+9hhHDm0lPFDSxk9uJif/G0Vdz1VyYCiAm6aPj5dH80555LqkVwI\nHA/8y8w+LWkI8LvUhtX7lMeK+deb27jlD6/tTxrb4gbfy0oLOWpIKZeefARHDS3lqCGljBtSQlFB\n4v9EXz7jSLbt3scvnn6DgUX5XPv+Md31UZxz7iDJJJI9ZtYkqUFSP2ALB6986JJw7PD+PLWiit+/\ntIEjh5Qw/ZihHDWkNPQy+jGouOCQzieJW2ccw4499Xx37nIG9C3gopP8P4tzrvslk0gWSRoA/ApY\nDNQCzydzcknTgZ8SLWx1r5l9v8X2GUTrtDcBDURrsy+QNJLo0tkQwIB7zOynccd9Afg80Aj82cy+\nmkw86fTFD4/jUycfwZB+hV02ppGbI3500UR27m3g5kdfoV/ffKYfM7RLzu2cc8mS2bsWP2x9Z2k0\n0C+Z9Ugk5QIrgY8A64mW3r3EzF6P26cE2BVWRTwOmGNm40ORyGFm9pKkUqIEdq6ZvS7pQ8A3gLPN\nrE7SYWa2pa1YJk+ebIsWLUr6c2aa3fsauOzeF3htw05+8+mTOHVsLN0hOed6AUmLzWxye/u1eh+J\npEktH8AgomrAk5KIYQpRocfVYf33h2gxbdjMau1AJism6n1gZhvN7KXwugZYBgwP+30O+L6Z1YXt\nbSaRbFBUkMfsq06iPFbMNQ8s4uW3tqc7JOdcFmnr0tYP29hmwGntnHs48Fbc+/XAyS13knQe8D3g\nMKK751tuHw2cALwQmo4Epkn6DtGNkV8xs4XtxNLrDSgq4IHPTOHCWf/gql+/yCMz38vYw0rTHZZz\nLgu02iMxsw+18WgviSTNzB4zs/HAuUTjJfuFS1+/Jxo72Rma84h6RqcQ1fyaowSDDpKulbRI0qKq\nqqquCrdHG9KvD7+9+mRyc3K4/L4X2bB9T7pDcs5lgWSq/34+DLY3vx8o6d+TOPcGDp7dNSK0JWRm\nzwIVkmLh5+QTJZEHzezRuF3XA49a5EWigfp3DQqY2T1mNtnMJpeVlSURbu8wOlbMbz8zhdq6Bi6/\n7wW21talOyTnXC+XTK2ta8xs/0V3M9sGXJPEcQuBcZLKJRUAnwQej99B0tjm3kQYdykEtoa2+4Bl\nZtZyffj/AT4UjjkSKACqk4gnaxw9rB+zrzqJt7fv4cpfv0jNXi8W6ZxLnWQSSW78paMwG6vdmx7M\nrAG4jmh1xWVEM7KWSpopaWbY7QLgNUlLgLuBi8Pg+/uAy4HTJC0Jj4+GY2YT9VxeIxrAvzJuwN4F\nJ40exC8uPZHlG2u45oFF7K1vTHdIzrleqt3pv5LuBI4AfhmaPgu8ZWZfTnFsXaa3T/9tyx+WbOCG\nh5fw4fFDmHXZJPJyk/nbwTnnumD6b5ybgL8TTbv9HDAP6PE3ALrIjInD+fY57+FvyzZz0+9fpanJ\nO2/Oua6VTBn5JmAWMEvSIGCEmfl1kgxyxXtHs21XPT/+20oGFuXzjbOP9orBzrkuk0z136eBc8K+\ni4Etkv5hZl9KcWyuC33xw2PZtnsf9y5Yw8DiAj7/obHpDsk510skU2urv5ntlPRvwANmdoukdkuk\nuJ5FEt/82AR27KnnzidW0L9vPpedckS6w3LO9QLJJJK8UPvqIqIaVy5D5eSIOy48jp176vl/f3iN\nAUX5fOy4w9MdlnMuwyUz2H4r0RTeSjNbKKkCWJXasFyq5OfmcPelkzjpiEF86eElPLMyO+76d86l\nTruJxMweMbPjzOzfw/vVZnZB6kNzqdInP5dfXTmZsYeVMvO3i1m8blu6Q3LOZbC2qv9+NTz/h6Sf\ntXx0X4guFfr3zeeBq6cwpF8hV/36RZ5ekfVFlJ1zHdRWj2RZeF5ENFur5cNluLLSQh685hRGDCzi\n6t8s5JfPvIEXCXDOHapDWtgqU2Xzne3J2L2vgRsfeYU/v7qRcycezvcvOI4++bnpDss5l2bJ3tne\n6qwtSY+3tg3AzM7pSGCu5ykqyOOuT53AhKf78YO/ruCNql3cc8WJDOvfN92hOecyQFvTf99LtDDV\nfxEtKuW3Qvdikvj8h8Zy1JBSbnh4CR//j+eYddkkJo8elO7QnHM9XFtjJEOBrwPHAD8lWnu92sye\nMbNnuiM41/1OnzCEx/79VEoKc7nkV//koRffTHdIzrkerq0VEhvN7H/N7Eqi1QgrgaclXddt0bm0\nGDeklD98fiqnVAzm5kdf5ZY/vEZ9Y1O6w3LO9VBt3kciqVDS+cDvgM8DPwMe647AXHr1L8rn11ed\nxDXTyrn/+XVcft8LvLNrX7rDcs71QG3dR/IA8DwwCfi2mZ1kZreZWavL5breJS83h2+cPYEfXXQ8\nL725nXPuWsCyjTvTHZZzrodpq0dyGTAOuB74h6Sd4VEjKanfJpKmS1ohqVLSzQm2z5D0SlgBcZGk\nqaF9pKSnJL0uaamk6xMc+2VJ1rzGu0ud8yeNYM5n30t9YxPn//wf/OXVjekOyTnXg7Q1RpJjZqXh\n0S/uUWpm/do7cViS927gLGACcImkCS12mwccb2YTgauBe0N7A/BlM5tAND7z+fhjJY0EzgB8JLib\nTBw5gD9eN5Xxw0r53IMv8aO/rvBFspxzQHJFGztqClGhx9Vmto9offUZ8TuYWW3ceuvFgIX2jWb2\nUnhdQ3SX/fC4Q39MtEqj/ybrRof168ND157CJ04cwc/+Xslnf7eY2rqGdIflnEuzVCaS4UT3oTRb\nz8HJAABJ50laDvyZqFfScvto4ASie1mQNAPYYGYvd33Irj2FebncceFx3PLxCfx9+RbO//lzrNu6\nK91hOefSKJWJJClm9piZjQfOBW6L3yapBPg9cENYXKuI6N6Wb7Z3XknXhnGXRVVVXiq9K0ni0+8r\n54Grp7Clpo5z7nqOBauq0x3WQRqbjC01e1n69g6eXrGFhWvfSXdIzvVaKau1Jem9wLfM7Mzw/msA\nZva9No5ZDUwxs2pJ+cCfgCfM7Edh+7FE4yq7wyEjgLfDMZtaO6/X2kqdN7fu5t8eWEjlllq+cfYE\nrn7f6JStB29m7NhTT1VNXfSobfEcHtW1dWzdtY+W/2vfeOZRvsSwc4eg07W2usBCYJykcmAD8Eng\nU/E7SBoLvGFmJmkSUAhsVfSb6D5gWXMSATCzV4HD4o5fC0w2s57153AWGTW4iEf//X18ec4SbvvT\n6zy7sorDB/SJ2+NAUonPLy1TzcHbojf1jU1UxyeJ2jrqG9/9h09Bbg5lpYXESgsZMbCIE0YNpKyk\ngLLSwv2PB55fx51PrMDMuO60cV3wyZ1zzVKWSMysIdwF/wSQC8w2s6WSZobts4ALgCsk1QN7gItD\nUpkKXA68KmlJOOXXzWxuquJ1HVdSmMcvLj2Ru56q5L9efHP/vSbxv/IP7h1YK+0HH5OXI2IlUSIY\ne1jpQYmhrOTAc7++ee32giaOHEiOxA/+upImgy9+2JOJc13Fy8i7rNHYZNz4yMs8+q8N3HD6OG44\n/ch0h+Rcj9YTLm0516Pk5og7P3E8kvjJ31bRZPCl08elbEzHuWzhicRlldwccceFx5Ej+Nm8VWDG\nlz5ypCcT5zrBE4nLOrk54vYLjiNH4md/r6TJ4MtneDJxrqM8kbislJMjvnf+sUhw11OVNJlx45lH\neTJxrgM8kbislZMjvnvesUji50+/QZPBTdM9mTh3qDyRuKyWkyO+c+4x5AhmPfMGZsbNZ433ZOLc\nIfBE4rIKYkJ4AAATIElEQVReTo74/849hhyJXz67miYzvv7Roz2ZOJckTyTOEdUPu3XGe8jNEb+a\nv4Ymg/97ticT55LhicS5QBK3fHwCEty3YA1NZnzzYxM8mTjXDk8kzsWRFCUPxOzn1mBGSC6eTJxr\njScS51qQxP/72NHkCO4NPZNvn/MeTybOtcITiXMJSOIbZx9NTo64JwzA33rOMeTkeDJxriVPJM61\nQhJfO2s8EvzymdWYwW0zPJk415InEufaIImbp48nR+IX4abF75zrycS5eJ5InGuHJL565lHkCO5+\n6g0aGpv49oz3UFTg/3ycA08kziVFEl854yhyQ6HHp1dWccPp47h48kjycnPSHZ5zaZXSha0kTQd+\nSrRC4r1m9v0W22cAtwFNQANwg5ktkDQSeAAYQrRo3j1m9tNwzJ3Ax4F9wBvAp81se1tx+MJWrist\nXvcO35u7nEXrtlFRVsxXzxzPme8ZkvGzuuoaGlm8dhvzK6tZuamG0bFijh7Wj/FDSxk3pITCvNx0\nh+i6WbILW6UskUjKBVYCHwHWE63hfomZvR63TwmwKyyvexwwx8zGSxoGDDOzlySVAouBc83sdUln\nAH8PS/neDmBmN7UViycS19XMjCdf38zt/7ucN6p2ceIRA/naWeOZPHpQukNLmpmxYnMN81dWM7+y\nmhfXbGVvfRN5OWJ0rJi33tlNXUMTEJXeH1NWzPih/aLkMqyUo4f2Y0i/woxPoK51PWGFxClApZmt\nDgE9BMwA9icSM6uN27+YsGS3mW0ENobXNZKWAcOB183sr3HH/BO4MIWfwbmEJHHGe4Zy2vjDeGTx\nen785EounPU8H5kwhJumH8XYw0rTHWJCm3fuZcGqahZURo+qmjoAxpQV88mTRjF1bIxTxgympDCP\nxiZjTfUulm/ayfKNNSzbuJPF67bx+Mtv7z/fwKJ8xg8NiWVYP44e2o9xQ0rok++9l2ySyh7JhcB0\nM/u38P5y4GQzu67FfucB3wMOA842s+dbbB8NPAscY2Y7W2z7I/Cwmf0uwc+/FrgWYNSoUSeuW7eu\niz6Zc++2e18DsxesYdYzq9m9r4GLTxrJDacfyZB+fdIe1wur32H+qmoWVFaxcnP0t9ug4gLeNzbG\ntHExpo6NcfiAvkmfc8fu+ii5bIqSy7JNNazYtJO99VHvJUdQUVbC+KFRcjl2eH9OHTPYx5IyUE+4\ntJVUIonb//3AN83s9Li2EuAZ4Dtm9miL/b8BTAbOt3Y+hF/act1la20d//H3Sh58YR15OTl8Zmo5\nn/1ABaV98rvl5zc2Ga9u2MGCVVXMX1XNS29uo77RKMjLYcroQUwNiWPCsH5dOoW5sclYt3UXyzfV\nsHzjTl7fWMPyTTtZv20PACMH9eXq95Vz0eSRFBf6HJ9M0RMSyXuBb5nZmeH91wDM7HttHLMamGJm\n1ZLygT8BT5jZj1rsdxXwWeDDZra7vVg8kbjutm7rLn7w15X88eW3GVRcwBdOG8ulJx9BQV7X/VVu\nZlTV1LEs9AxeWb+d5yq3smNPPQAThvWLehzjYpw0elBaLjft3FvPc6uquXfBGhav20a/PnlcesoR\nXHXq6LT31lz7ekIiySMabP8wsIFosP1TZrY0bp+xwBthsH0S8EdgRNh8P/COmd3Q4rzTgR8BHzCz\nqmRi8UTi0uWV9dv53tzlPL96K6MGFXHjmUdx9rHDDrk3UNfQSOWWWpZtjP7iXxbGLbbu2rd/n+ED\n+nLqmMFMHRfjfWNjxEoKu/rjdMriddu4d/5qnli6idwccc7xw7nm/eWMH9ov3aG5VqQ9kYQgPgr8\nhGj672wz+46kmQBmNkvSTcAVQD2wB7gxTP+dCswHXiWaGgzwdTObK6kSKAS2hvZ/mtnMtuLwROLS\nycx4emUVt/9lOcs31XDciP7cfNZ4Th0TS7hvfC9j+cadLNtYwxtVtTQ0Rf9WC/NyOGpo6f4xiGgm\nVSkDigq6+6N1yLqtu5i9YA1zFq1nT30j08bFuPb9FUwdG/MZYD1Mj0gkPYUnEtcTNDYZj/1rAz/6\n6wre3rGXDxxZxr9NK2fLzrowaP3uXsaw/n2i2VDDSvdPvR09uKhXDFxv372PB194k9/8Yy1VNXWM\nH1rKNdMq+Pjxh3fpJUDXcZ5I4ngicT3J3vpG7v/HWu5+qpKdexuAzO9ldEZdQyN/WPI2985fzcrN\ntQzpV8hVp5bzqZNH0b9v90xScIl5IonjicT1RNt372PR2m2MjhX3ml5GZ5gZz66q5lfPrmZBZTVF\nBblcfNJIrn5fOSMHFaU7vKzkiSSOJxLnMsvSt3dw3/w1PP7y2zSZcdaxw7hmWgUTRw5Id2hZxRNJ\nHE8kzmWmjTv28Jt/rOU/X3iTmr0NTD5iIGe8ZwjTxpUxfmhp1g/ONzYZW3fVUV2zj+raOqpq6qiu\nrYt7vY+bzxrPMcP7d+j8PaFEinPOdcqw/n352llH84XTxvHwwrd4eOGbfHfucmA5sZLC/XfmTxsX\n47Becl9KY5Pxzq59LRJClBSaXzc/v7NrH00J+gJ98nMoKy0kVlJIXUNjymP2HolzLqNs2rGX+auq\nWFBZzXOV1VTXRrPcjhpSGt25Py7GyeWDMma9mMYm47UNO1hQWc38VVW8tG47+xqb3rVfYd6B5BAr\nKaSstJCykoIDbaWFlIXn4oLcLumt+aWtOJ5InOudmpqMZZt2smBVNfNXVfPi2nfY19BEQW4OJx4x\nkGlHxpg2toz3HN61JWE6a/223VH9s1XVPPdGNdt3H6hGcOqYwYwcVLQ/QUTPBZQU5nX7pTxPJHE8\nkTiXHfbWN/LimndYUFnNsyurWL6pBoiqFO8vUjmujOGHUKSyK9Tsref5N7aGXkc1a6p3ATC0Xx+m\njovi6onVCDyRxPFE4lx2qqqp47nKap5dVcWCVdVsCWXzK8qKOXXMYIYPKCJWUnDgslBJIYNLCsjv\n5FTshsYmXl6/I7oEt6qaf721ncYmo29+LqdUDGLauDKmjYsx9rCSHj1hwBNJHE8kzjkzY+XmWuaH\nysiL122jtq4h4b4Di/L3j0XEwqWlWEnzGEQBZSV9iJUWMLi4kIK8HMyMdVt3M7+ymvkrq3h+9VZq\n9jYgwXHD+4eqy2VMOmJARq006YkkjicS51wiu+oa4mZHHZgpVV0bTamt2v+6jl37Es9+6t83n8K8\nnP29neED+jJtXIxp48o4dcxgBhZnbnUCn/7rnHPtKC7Mo7gwjyMGF7e77559jVHCCYklfjrurroG\nJo4awLRxZYweXNSjL1elgicS55xLQt+CXEYOKvJyLQlkd3Ef55xzneaJxDnnXKekNJFImi5phaRK\nSTcn2D5D0iuSlkhaFBa0QtJISU9Jel3SUknXxx0zSNKTklaF54Gp/AzOOefalrJEIikXuBs4C5gA\nXCJpQovd5gHHm9lE4Grg3tDeAHzZzCYApwCfjzv2ZmCemY0Lx78rQTnnnOs+qeyRTAEqzWy1me0D\nHgJmxO9gZrV2YP5xMWChfaOZvRRe1wDLgOFhvxlE67kTns9N4WdwzjnXjlQmkuHAW3Hv13MgGewn\n6TxJy4E/E/VKWm4fDZwAvBCahpjZxvB6EzCk60J2zjl3qNI+2G5mj5nZeKKexW3x2ySVAL8HbjCz\nnQmONUIvpiVJ14Zxl0VVVVUpiNw55xykNpFsAEbGvR8R2hIys2eBCkkxAEn5REnkQTN7NG7XzZKG\nhX2GAVtaOd89ZjbZzCaXlZV17pM455xrVcpKpEjKA1YCHyZKIAuBT5nZ0rh9xgJvmJlJmgT8kSjh\nQDT+8Y6Z3dDivHcCW83s+2Em2CAz+2o7sVQB6xJsigHVHfqA6ZfJsUNmx5/JsUNmx5/JsUPmxX+E\nmbX7l3hKa21J+ijwEyAXmG1m35E0E8DMZkm6CbgCqAf2ADea2YIwDXg+8CrQvMLL181srqTBwBxg\nFFFyuMjM3ulgfIuSqSPTE2Vy7JDZ8Wdy7JDZ8Wdy7JD58bcmpSVSzGwuMLdF26y417cDtyc4bgGQ\nsFiNmW0l6uU455zrAdI+2O6ccy6zZXsiuSfdAXRCJscOmR1/JscOmR1/JscOmR9/QlmxHolzzrnU\nyfYeiXPOuU7KykTSXjHJnk7SWkmvNhe7THc87ZE0W9IWSa/FtWVE8c1WYv+WpA3h+18SZif2OK0V\nP82g7761+Hv89y+pj6QXJb0cYv92aM+I7/5QZd2lrVBMciXwEaKyLQuBS8zs9bQGdggkrQUmm1lG\nzEeX9H6gFnjAzI4JbXcQ3SfUfD/QQDO7KZ1xJtJK7N8Cas3sB+mMrT3hht1hZvaSpFJgMVEFiavI\njO++tfgvood//4qWSCw2s9pwc/UC4HrgfDLguz9U2dgjabeYpOtaoWpBy3t9MqL4ZiuxZ4Q2ip9m\nynffVvHWHs0iteFtfngYGfLdH6psTCRJFZPs4Qz4m6TFkq5NdzAdlOnFN78Q1tKZnQmXJ1oUP824\n7z5B8dYe//1LypW0hKiM05NmlpHffTKyMZH0BlPDGi5nEa3V8v50B9QZbRXf7KF+AVQAE4GNwA/T\nG07b2ip+mgnffYL4M+L7N7PG8O90BDBF0jEttvf47z5Z2ZhIDqmYZE9kZhvC8xbgMaLLdZkmqeKb\nPZGZbQ6/JJqAX9GDv/9Wip9mzHefKP5M+v4BzGw78BQwnQz67g9FNiaShcA4SeWSCoBPAo+nOaak\nSSoOA49IKgbOAF5r+6ge6XHgyvD6SuAPaYzlkDT/IgjOo4d+/2HA9z5gmZn9KG5TRnz3rcWfCd+/\npDJJA8LrvkSTe5aTId/9ocq6WVuQuJhkmkNKmqQKol4IRLXS/rOnxy/pv4APElU+3QzcAvwPXVR8\nM5Vaif2DRJdVDFgLfDbuuneP0VrxU6Jxhkz47luL/xJ6+Pcv6TiiwfRcoj/Y55jZrV1ZdLYnycpE\n4pxzrutk46Ut55xzXcgTiXPOuU7xROKcc65TPJE455zrFE8kzjnnOsUTieuxJJmkH8a9/0oomNgV\n5/6NpAu74lzt/JxPSFom6akW7aPD5/tCXNtdkq5q53wzJV3Rzj5XSbqrlW21idq7Svhc8ZWSrwml\nfHpkGRPXNTyRuJ6sDjhfUizdgcSTlHcIu38GuMbMPpRg2xbg+nBjbFLMbJaZPXAIP7/LHOLnRtLl\nwBeAM81sW2qicj2BJxLXkzUQLU36pZYbWvYomv/SlvRBSc9I+oOk1ZK+L+nSsDbEq5LGxJ3mdEmL\nJK2U9LFwfK6kOyUtDEUBPxt33vmSHgfeteSApEvC+V+TdHto+yYwFbhP0p0JPl8VMI8DdzrHn2+M\npP8Nf83PlzQ+tH9L0lfC65NCjEtCzPF3eB8ejl+lqGR//Ll/rGiNjHmSykLbREn/DOd7rLkHIelp\nST9RtO7N9aGH9ZqidTaeTfCZmn/GRcDNwBmZstyB6zhPJK6nuxu4VFL/QzjmeGAmcDRwOXCkmU0B\n7iX6C7nZaKI6TWcDsyT1IepB7DCzk4CTgGsklYf9JwHXm9mR8T9M0uHA7cBpRHdcnyTpXDO7FVgE\nXGpmN7YS6+3AVxStkxPvHuALZnYi8BXg5wmO/TXRXd0TgcYW2yYCFwPHAhdLaq4vVwwsMrP3AM8Q\n3akP8ABwk5kdR3Qn+S1x5yows8lm9kPgm0Q9jOOBc1r5TEcAdxElkU2t7ON6EU8krkcL1V4fAL54\nCIctDGtZ1AFvAH8N7a8SJY9mc8ysycxWAauB8US1y65QVP77BWAwMC7s/6KZrUnw804CnjazKjNr\nAB4EkqrIbGarw8/5VHObomq3pwKPhDh+CcTXlyLUcSo1s+dD03+2OPU8M9thZnuJelBHhPYm4OHw\n+nfA1JCkB5jZM6H9/hbxPxz3+jngN5KuISr/kUgV8CbRAlQuCxzSNU/n0uQnwEtEf4E3ayD8ISQp\nB4gfZ6iLe90U976Jg/+fb1kfyAAR9QSeiN8g6YPAro6F367vAv9N1EOA6HNtDz2Njor/Dhpp/d96\nMjWS9n9uM5sp6WSiXtxiSSea2dYW++8GPgrMl7TFzB48hLhdBvIeievxQlG7OUSXnZqtBU4Mr88h\nWoHuUH1CUk4YN6kAVgBPAJ9TVL4cSUcqqrLclheBD0iKhUtUl3AgKbTLzJYT9Ro+Ht7vBNZI+kSI\nQZKOb3HMdqAm/FKHqIp1MnKA5rGlTwELzGwHsE3StNB+eWvxSxpjZi+Y2TeJeh4jE+0XljiYDnxX\n0plJxuYylCcSlyl+SFSBt9mviH55vwy8l471Ft4kSgJ/AWaGy0D3Ev1SfykMXv+SdnruofLszURr\nTrwMLDazQy0P/h2itXGaXQp8Jny+pSReDvozwK/C5a9iYEcSP2cX0SJLrxGN6dwa2q8E7pT0CtH4\nyq2tHH9n86QC4B9EnzehcBnwHGC2pB69ZojrHK/+61yGklTSvC64pJuBYWZ2fZrDclnIx0icy1xn\nS/oa0b/jdcBV6Q3HZSvvkTjnnOsUHyNxzjnXKZ5InHPOdYonEuecc53iicQ551yneCJxzjnXKZ5I\nnHPOdcr/D8AgLb1OfIYNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3190feb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print(\"The optimal number of neighbors is %d\" % optimal_k)\n",
    "\n",
    "# plot misclassification error vs k\n",
    "plt.plot(neighbors, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.670997076973\n",
      "accuracy: 0.670997076973\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.00      0.00      0.00        72\n",
      "        2.0       0.00      0.00      0.00        67\n",
      "        3.0       0.00      0.00      0.00       229\n",
      "        4.0       0.33      0.00      0.01       646\n",
      "        5.0       0.67      1.00      0.80      2065\n",
      "\n",
      "avg / total       0.52      0.67      0.54      3079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Try Pick 29 neighbors.\n",
    "\n",
    "# instantiate learning model \n",
    "model = KNeighborsClassifier(n_neighbors=29)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "knn2_expected = y_test\n",
    "knn2_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(knn2_expected, knn2_predicted)))\n",
    "print(metrics.classification_report(knn2_expected, knn2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. Write a short description of the improvement you were able to make in your prediction. Make sure your answer is no longer than four paragraphs, and should at minimum answer these questions:\n",
    "*\tWhat combination of classifiers and settings did you use and why?\n",
    "*\tWhich model fit “best” and what metric did you use for the comparison? Why? \n",
    "*\tAre you happy with the results? Why or why not?  What could you do to improve on the “best” model’s performance?\n",
    " Audience: technical – fellow data scientists or other technical staff.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried five different settings, and four different models: Decision Tree, Naive Bayes, Logistic Regression, and KNN models.  \n",
    "For each setting, I ran several models, and I ran 12 models in total. The results are listed below in Table 1 and Table 2.\n",
    "\n",
    "Here are some of the preprocessing steps I tried.  I used both modified NLTK and Sklean stop words to remove from the review text. I used cleaned text by replacing plural words such as \"guitars\" to \"guitar\", and \"years\" to \"year\"...etc.  I also tried Porter stemming.  I used lower case text in all cases.  I set ngram to 1 or 2 so one or two words term would return from the vectorizers.  I set min_df and max_df between 5% and 95% to reduce number of qualifying feature spaces.  When I want to higher number of feature spaces to feed into PCA for KNN model I set a much smaller 0.1% min_df. The detail settings of each batch of models' runs are listed below:\n",
    "\n",
    "* **Setting 1** - Count vectorizer on cleaned text, Sklean stop words.\n",
    "* **Setting 2** - Count vectorizer on Porter stemmed text, Sklean stop words.\n",
    "* **Setting 3** - Tfididf vectorizer on cleaned text, NLTK stop words.\n",
    "* **Setting 4** - Count vectorizer on cleaned text, Sklean stop words, min_df set to 0.1%. PCA components set to 800 which captures 83% of the variance explained.\n",
    "* **Setting 5** - Tfididf vectorizer on cleaned text, NLTK stop words, min_df set to 0.1%, cosine similarity. KNN neighbor set to 29 using elbow method and cross validation.\n",
    "\n",
    "Table 1 shows accuracy ratios on the all twelve models I ran. The second table shows precision ratios on poor (1/5) overall rating reviews.  This is because the base model did not do well on those lower rating predictions.  I want to see which model is better at predicting 1/5 overall rating products.  Precision and recall ratio shows how good model is at predicting true positive. $$Precision = \\frac{TP}{{TP} + {FP}}$$ $$Recall = \\frac{TP}{{TP} + {FN}}$$ \n",
    "\n",
    "[Wiki Reference](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
    "\n",
    "\n",
    "                                   Table 1. Accuracy ratios \n",
    "| Accuracy      | Base Setting  |  Setting 1 | Setting 2 | Setting 3 | Setting 4 | Setting 5  |\n",
    "| :------------:|:-------------:|:-----------------------------------------------------------:|\n",
    "| Decision Tree | 57.5%         |   52.6%    |   53.3%   |   53.9%   |   50.7%   |            |\n",
    "| Naive Bayes   | 66.7%         |   65.3%    |   64.7%   |   67.1%   |           |            |\n",
    "| Logistic Reg  | 65.1%         |   67%      |   67.3%   |   67.3%   |   66.6%   |            |\n",
    "| KNN           | 64.4%         |            |           |           |           |   67.1%    |\n",
    "\n",
    "\n",
    "                                   Table 2. Precision ratios on 1/5 overall rating product reviews\n",
    "| Precision     | Base Setting  |  Setting 1 | Setting 2 | Setting 3 | Setting 4 | Setting 5  |\n",
    "| :------------:|:-------------:|:-----------------------------------------------------------:|\n",
    "| Decision Tree | 23%           |     4%     |     4%    |    9%     |     3%    |            |\n",
    "| Naive Bayes   | 50%           |    26%     |    19%    |    0%     |           |            |\n",
    "| Logistic Reg  | 58%           |    75%     |    60%    |    0%     |    39%    |            |\n",
    "| KNN           | 5%            |            |           |           |           |     0%     |\n",
    "\n",
    "\n",
    "The logistic Regression models using setting 1 (count vectorizer on cleaned text and SKL stop words) produced an overall accuracy of 67% and 75% precision on 1/5 overall rating review predictions.  This is a better model than the base model prediction accuracy and precision on 1/5 overall rating review if we care the lower rating prediction result. Some disappointments include:\n",
    "\n",
    "* Unfortunately, the PCA dimension reduction technique used on setting 4 did not yields a better accuracy on Decision Tree and Logistic Regression models.\n",
    "* Stemmed text works well but not as good as cleaned text by customer replacement.\n",
    "* Cross validation elbow method selected 29 neighbors for KNN model, the model yields only a slightly better accurate KNN model than the base model.  \n",
    "* KNN model rans much slower with cosine similarity, the results did not improve vs with Euclidian distance.\n",
    "\n",
    "To improve on the \"best\" logistic regression model I would like to look for more customer replacement words I can add, and find other variables (besides just the text) that can improve prediction results. I could use ensemble model approach to combine multiple models together to get the prediction results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T3. Perform K-means clustering on your dataset.  Store the cluster assignments in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv1 = CountVectorizer(lowercase=True, \n",
    "                     stop_words=new_skl_stopwords,\n",
    "                     binary=False,\n",
    "                     max_df=0.95, \n",
    "                     min_df=0.01,\n",
    "                     ngram_range = (1,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10261, 690)\n",
      "<class 'list'> 690\n"
     ]
    }
   ],
   "source": [
    "cv_dm = cv1.fit_transform(amazonReview['cleantext'])\n",
    "print(cv_dm.shape)\n",
    "\n",
    "names = cv1.get_feature_names()\n",
    "print(type(names), len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# finding an optimal value for k\n",
    "k_range = range(3,20)\n",
    "k_means_set = [KMeans(n_clusters=k,init='k-means++', max_iter=100, random_state = 42).fit(cv_dm) for k in k_range]\n",
    "centroids_list = [km_result.cluster_centers_ for km_result in k_means_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#centroids_list_df = np.array(centroids_list)\n",
    "#print(centroids_list_df.shape)\n",
    "#centroids_list_df.to_pickle(\"centroids_list.bin\")\n",
    "#centroidsList_df = pd.read_pickle('centroids_list.bin')\n",
    "#centroids_list = centroidsList_df.values.T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calc euclidean dist from each point to each cluster center\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "cv_dm_array = cv_dm.toarray()\n",
    "\n",
    "k_euclid = [cdist(cv_dm_array, thing, 'euclidean') for thing in centroids_list]\n",
    "distance_set = [np.min(k_euc, axis=1) for k_euc in k_euclid]\n",
    "\n",
    "# total within-cluster sum of squares\n",
    "wcss = [np.sum(distance**2) for distance in distance_set]\n",
    "\n",
    "# total sum of squares\n",
    "tss  = np.sum(pdist(cv_dm_array)**2) / cv_dm_array.shape[0]\n",
    "\n",
    "# between cluster sum of squares\n",
    "bss = tss - wcss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Chart 1. Withiness sum of squares over Total sum of squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10afc320>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEXCAYAAAC3c9OwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZlaUE4SZmRXlBGFmZkX9f2bDAnAPf7yGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a5c240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot elbow chart wss/tss\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(k_range, wcss/tss*100, '^-')\n",
    "ax.set_ylim((0,100))\n",
    "plt.grid(True)\n",
    "plt.xlabel('K n_clusters')\n",
    "plt.ylabel('% Variance Explained')\n",
    "plt.title('% WSS over TSS Variance Explained vs K')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Chart 2. Between sum of squares over Total sum of squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10c938d0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEXCAYAAAC3c9OwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c43198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot elbow chart bss/tss\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(k_range, bss/tss*100, '^-')\n",
    "ax.set_ylim((0,100))\n",
    "plt.grid(True)\n",
    "plt.xlabel('K n_clusters')\n",
    "plt.ylabel('% Variance Explained')\n",
    "plt.title('% BSS over TSS Variance Explained vs K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.28774259,  10.07195278,  11.45516744,  12.55474367,\n",
       "        13.44645198,  14.56308333,  15.25230072,  16.15836422,\n",
       "        16.71546635,  17.15141151,  17.9429841 ,  18.40837488,\n",
       "        18.79351871,  19.29252439,  19.8985848 ,  20.12347189,  20.74906637])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bss/tss*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create 16 clusters\n",
    "My_k = 16\n",
    "km = KMeans(n_clusters=My_k, init='k-means++', max_iter=100, random_state = 42)\n",
    "news_k = km.fit(cv_dm_array)\n",
    "clusters = km.labels_.tolist()\n",
    "amazonReview['clusters'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7     6560\n",
      "1     1034\n",
      "2      754\n",
      "5      479\n",
      "15     422\n",
      "6      261\n",
      "3      199\n",
      "11     131\n",
      "0      122\n",
      "9      108\n",
      "13     104\n",
      "12      65\n",
      "8       13\n",
      "14       4\n",
      "4        4\n",
      "10       1\n",
      "Name: clusters, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(amazonReview['clusters'].value_counts())\n",
    "#amazonReview.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster1 = amazonReview[(amazonReview['clusters'] == 0)]\n",
    "#print(cluster1.index)\n",
    "cluster2 = amazonReview[(amazonReview['clusters'] == 1)]\n",
    "cluster3 = amazonReview[(amazonReview['clusters'] == 2)]\n",
    "cluster4 = amazonReview[(amazonReview['clusters'] == 3)]\n",
    "cluster5 = amazonReview[(amazonReview['clusters'] == 4)]\n",
    "cluster6 = amazonReview[(amazonReview['clusters'] == 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 690)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound</th>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedal</th>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tone</th>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guitar</th>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play</th>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "amp       693\n",
       "sound     597\n",
       "pedal     394\n",
       "like      313\n",
       "tone      307\n",
       "use       297\n",
       "good      214\n",
       "just      211\n",
       "guitar    202\n",
       "play      188"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dm_array = cv_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "cluster1_cv_dm_array = cv_dm_array[cluster1.index];\n",
    "print(cluster1_cv_dm_array.shape)\n",
    "cluster1_count = np.sum(cluster1_cv_dm_array, axis = 0).tolist()\n",
    "cluster1_count_df = pd.DataFrame(cluster1_count, index = names, columns = ['count'])\n",
    "cluster1_count_df.sort_values(['count'], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8035, 690)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>2696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guitar</th>\n",
       "      <td>2664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>2642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>2269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>string</th>\n",
       "      <td>2214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>1919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>1866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound</th>\n",
       "      <td>1851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy</th>\n",
       "      <td>1634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "great    2696\n",
       "guitar   2664\n",
       "use      2642\n",
       "good     2269\n",
       "string   2214\n",
       "work     2063\n",
       "like     1919\n",
       "just     1866\n",
       "sound    1851\n",
       "buy      1634"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dm_array = cv_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "cluster2_cv_dm_array = cv_dm_array[cluster2.index];\n",
    "print(cluster2_cv_dm_array.shape)\n",
    "cluster2_count = np.sum(cluster2_cv_dm_array, axis = 0).tolist()\n",
    "cluster2_count_df = pd.DataFrame(cluster2_count, index = names, columns = ['count'])\n",
    "cluster2_count_df.sort_values(['count'], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235, 690)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>string</th>\n",
       "      <td>1778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guitar</th>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound</th>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play</th>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "string   1778\n",
       "guitar    632\n",
       "sound     383\n",
       "play      326\n",
       "like      253\n",
       "use       239\n",
       "just      216\n",
       "good      196\n",
       "set       192\n",
       "make      190"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dm_array = cv_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "cluster3_cv_dm_array = cv_dm_array[cluster3.index];\n",
    "print(cluster3_cv_dm_array.shape)\n",
    "cluster3_count = np.sum(cluster3_cv_dm_array, axis = 0).tolist()\n",
    "cluster3_count_df = pd.DataFrame(cluster3_count, index = names, columns = ['count'])\n",
    "cluster3_count_df.sort_values(['count'], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(833, 690)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pedal</th>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound</th>\n",
       "      <td>1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedals</th>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "pedal    1414\n",
       "sound    1397\n",
       "use      1250\n",
       "like      841\n",
       "just      779\n",
       "amp       760\n",
       "great     653\n",
       "good      633\n",
       "make      559\n",
       "pedals    525"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dm_array = cv_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "cluster4_cv_dm_array = cv_dm_array[cluster4.index];\n",
    "print(cluster4_cv_dm_array.shape)\n",
    "cluster4_count = np.sum(cluster4_cv_dm_array, axis = 0).tolist()\n",
    "cluster4_count_df = pd.DataFrame(cluster4_count, index = names, columns = ['count'])\n",
    "cluster4_count_df.sort_values(['count'], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266, 690)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pick</th>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play</th>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guitar</th>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grip</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>string</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>used</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "pick     1217\n",
       "play      214\n",
       "guitar    177\n",
       "like      173\n",
       "use       173\n",
       "just      137\n",
       "grip      100\n",
       "string     98\n",
       "great      96\n",
       "used       90"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dm_array = cv_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "cluster5_cv_dm_array = cv_dm_array[cluster5.index];\n",
    "print(cluster5_cv_dm_array.shape)\n",
    "cluster5_count = np.sum(cluster5_cv_dm_array, axis = 0).tolist()\n",
    "cluster5_count_df = pd.DataFrame(cluster5_count, index = names, columns = ['count'])\n",
    "cluster5_count_df.sort_values(['count'], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(782, 690)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>guitar</th>\n",
       "      <td>2746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strap</th>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>string</th>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play</th>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound</th>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "guitar   2746\n",
       "strap     637\n",
       "use       620\n",
       "string    550\n",
       "just      548\n",
       "like      482\n",
       "good      426\n",
       "make      417\n",
       "play      401\n",
       "sound     389"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dm_array = cv_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "cluster6_cv_dm_array = cv_dm_array[cluster6.index];\n",
    "print(cluster6_cv_dm_array.shape)\n",
    "cluster6_count = np.sum(cluster6_cv_dm_array, axis = 0).tolist()\n",
    "cluster6_count_df = pd.DataFrame(cluster6_count, index = names, columns = ['count'])\n",
    "cluster6_count_df.sort_values(['count'], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. Write a short description of the outcome of your clustering exercise. Make sure your answer is no longer than four paragraphs, and should at minimum answer these questions:\n",
    "*\tHow many clusters did you “find”? Why did you select that number? \n",
    "*\tCan you easily describe your clusters with a text label?  If so, what are the labels and how do they help?  If not, why not? \n",
    "Audience: general – management or non-technical staff. NOTE: this is a GENERAL AUDIENCE RESPONSE - be VERY careful with how you describe the clustering exercise.  Detailed descriptions of K-means is not required but any discussion of them must be NON TECHNICAL (but not fluffy).   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I selected six clusters.  I tried three to twenty clusters.  The six clusters shows unique/distinct groups, and within each group text key terms are similar to each other (see chart 1 and chart 2 above). \n",
    "\n",
    "The details of the six groups are listed below.  There are total of 10,261 reviews in the dataset, and 690 key terms (one or two words terms) retrieved from the text.  The number of items in each group, and the most frequent terms are listed in table 3 below.  \n",
    "\n",
    "                                         Table 3.  Group numbers and most frequent terms\n",
    "| Group      | Numbers of reviews |  most frequent Terms     |            \n",
    "|:----------:|:------------------:|:------------------------:|\n",
    "| Group 1    | 110                |   amp, sound             |\n",
    "| Group 2    | 8035               |   great, guitar, use\t |\n",
    "| Group 3    | 235                |   string, guitar\t     |\n",
    "| Group 4    | 833                |   pedal, sound, use\t     |\n",
    "| Group 5    | 266                |   pick           \t     |\n",
    "| Group 6    | 782                |   guitar, strap, use     |\n",
    "\n",
    "\n",
    "From this data I can easily describe the six clusters. Group one must is about amps and sounds of the instruments, group two are very general category, group 3 are string and guitars, group 4 are pedals, group 5 are picks, group 6 is strap, guitars.  If I choose a higher number of clusters then group 2 \"general category\" will further divide into smaller groups, but some of the other groups would not have unique key terms.  Therefore, I ended up six clusters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
