{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIA 6304 Text Mining, Fall 2017\n",
    "## Assignment 2\n",
    "### Stuent:  Leonardo Ji\n",
    "### 9/3/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**T1.**  Using the data frame from Assignment 1 or another that you create with at least one column of text to be analyzed, instantiate a count vectorizer to create a bag of words. Use the default to convert to lower case.  Generate a vector space model. Try various combinations of vectorizer settings like we did in class: changing case, eliminating stop words, using min and max document frequency settings, choosing n-grams, etc. Try at least 3 different versions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![R-blogger news site](https://www.r-bloggers.com/wp-content/uploads/2016/04/R_02_2016-05-01.png \"R-blogger\")\n",
    "I want to use R-blogger news site data from web scrapping technique used in the last class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd   #we almost always need pandas because we like data frames\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "pd.set_option('display.max_colwidth', 150) #important for getting all the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# R-Blogger news\n",
    "page = requests.get('https://www.r-bloggers.com')\n",
    "\n",
    "soup = BeautifulSoup(page.text, \"html5lib\")\n",
    "#print(type(soup))\n",
    "#print (soup.prettify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Category</th>\n",
       "      <th>author</th>\n",
       "      <th>Date</th>\n",
       "      <th>link</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A guide to parallelism in R</td>\n",
       "      <td>Post</td>\n",
       "      <td>Florian Privé</td>\n",
       "      <td>September 4, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/a-guide-to-parallelism-in-r/</td>\n",
       "      <td>In this post, I will talk about parallelism in R. This post will likely be biased towards the solutions I use. For example, I never use mcapply no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyzing Google Trends Data in R</td>\n",
       "      <td>Post</td>\n",
       "      <td>Jake Hoare</td>\n",
       "      <td>September 4, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/analyzing-google-trends-data-in-r-2/</td>\n",
       "      <td>Google Trends shows the changes in the popularity of search terms over a given time (i.e., number of hits over time). It can be used to find searc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyond the basics of data.table: Smooth data exploration</td>\n",
       "      <td>Post</td>\n",
       "      <td>sindri</td>\n",
       "      <td>September 5, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/beyond-the-basics-of-data-table-smooth-data-exploration/</td>\n",
       "      <td>This exercise set provides practice using the fast and concise data.table package. If you are new to the syntax it is recommended that you start b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blocked Gibbs Sampling in R for Bayesian Multiple Linear Regression</td>\n",
       "      <td>Post</td>\n",
       "      <td>AO</td>\n",
       "      <td>September 5, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/blocked-gibbs-sampling-in-r-for-bayesian-multiple-linear-regression/</td>\n",
       "      <td>In a previous post, I derived and coded a Gibbs sampler in R for estimating a simple linear regression. In this post, I will do the same for multi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calculating Marginal Effects Exercises</td>\n",
       "      <td>Post</td>\n",
       "      <td>BC Mullins</td>\n",
       "      <td>September 4, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/calculating-marginal-effects-exercises/</td>\n",
       "      <td>A common experience for those in the social sciences migrating to R from SPSS or STATA is that some procedures that happened at the click of a but...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              Headline  \\\n",
       "0                                          A guide to parallelism in R   \n",
       "1                                    Analyzing Google Trends Data in R   \n",
       "2             Beyond the basics of data.table: Smooth data exploration   \n",
       "3  Blocked Gibbs Sampling in R for Bayesian Multiple Linear Regression   \n",
       "4                               Calculating Marginal Effects Exercises   \n",
       "\n",
       "  Category         author               Date  \\\n",
       "0     Post  Florian Privé  September 4, 2017   \n",
       "1     Post     Jake Hoare  September 4, 2017   \n",
       "2     Post         sindri  September 5, 2017   \n",
       "3     Post             AO  September 5, 2017   \n",
       "4     Post     BC Mullins  September 4, 2017   \n",
       "\n",
       "                                                                                              link  \\\n",
       "0                                          https://www.r-bloggers.com/a-guide-to-parallelism-in-r/   \n",
       "1                                  https://www.r-bloggers.com/analyzing-google-trends-data-in-r-2/   \n",
       "2              https://www.r-bloggers.com/beyond-the-basics-of-data-table-smooth-data-exploration/   \n",
       "3  https://www.r-bloggers.com/blocked-gibbs-sampling-in-r-for-bayesian-multiple-linear-regression/   \n",
       "4                               https://www.r-bloggers.com/calculating-marginal-effects-exercises/   \n",
       "\n",
       "                                                                                                                                                 excerpt  \n",
       "0  In this post, I will talk about parallelism in R. This post will likely be biased towards the solutions I use. For example, I never use mcapply no...  \n",
       "1  Google Trends shows the changes in the popularity of search terms over a given time (i.e., number of hits over time). It can be used to find searc...  \n",
       "2  This exercise set provides practice using the fast and concise data.table package. If you are new to the syntax it is recommended that you start b...  \n",
       "3  In a previous post, I derived and coded a Gibbs sampler in R for estimating a simple linear regression. In this post, I will do the same for multi...  \n",
       "4  A common experience for those in the social sciences migrating to R from SPSS or STATA is that some procedures that happened at the click of a but...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BSobj = soup.find_all(\"div\",{\"class\":\"twopost\"})\n",
    "\n",
    "headlines = {}\n",
    "for item in BSobj:\n",
    "    date = item.find(\"div\",{\"class\":\"date\"}).get_text()\n",
    "    link = item.a[\"href\"]\n",
    "    author = item.find(\"a\",{\"rel\":\"author\"}).get_text()\n",
    "    excerpt = item.find(\"p\",{\"class\":\"excerpt\"}).get_text().replace('\\n', '')\n",
    "    headlines[item.a.get_text()] = {}\n",
    "    headlines[item.a.get_text()][\"category\"] = \"Post\"\n",
    "    headlines[item.a.get_text()][\"author\"] = author\n",
    "    headlines[item.a.get_text()][\"date\"] = date\n",
    "    headlines[item.a.get_text()][\"link\"] = link\n",
    "    headlines[item.a.get_text()][\"excerpt\"] = excerpt\n",
    "    \n",
    "#print(headlines)\n",
    "\n",
    "cnndf = pd.DataFrame.from_dict(headlines,orient=\"index\")\n",
    "#print(cnndf.shape)\n",
    "cnndf.reset_index(inplace=True)\n",
    "cnndf.columns = ['Headline', 'Category', 'author', 'Date', 'link', 'excerpt']\n",
    "textStr = cnndf['excerpt'].values\n",
    "cnndf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sklean documentation [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the first try I set binary to true, removed English stop word, and all other settings left in default settings. It returned 312 feature spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 312)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>14th</th>\n",
       "      <th>2017</th>\n",
       "      <th>abstractcontrol</th>\n",
       "      <th>accumulate</th>\n",
       "      <th>advocating</th>\n",
       "      <th>agreement</th>\n",
       "      <th>alexandria</th>\n",
       "      <th>...</th>\n",
       "      <th>viewed</th>\n",
       "      <th>vincent</th>\n",
       "      <th>virginia</th>\n",
       "      <th>visualization</th>\n",
       "      <th>vs</th>\n",
       "      <th>week</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>written</th>\n",
       "      <th>yang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  100  11  14th  2017  abstractcontrol  accumulate  advocating  \\\n",
       "0    0    0   0     0     0                0           0           0   \n",
       "1    0    0   0     0     0                0           0           0   \n",
       "2    0    0   0     0     0                0           0           0   \n",
       "3    0    0   0     0     0                0           0           0   \n",
       "4    0    0   0     0     0                0           0           0   \n",
       "\n",
       "   agreement  alexandria  ...   viewed  vincent  virginia  visualization  vs  \\\n",
       "0          0           0  ...        0        0         0              0   0   \n",
       "1          0           0  ...        0        0         0              0   0   \n",
       "2          0           0  ...        0        0         0              0   0   \n",
       "3          0           0  ...        0        0         0              0   0   \n",
       "4          0           0  ...        0        0         0              0   0   \n",
       "\n",
       "   week  working  world  written  yang  \n",
       "0     0        0      0        0     0  \n",
       "1     0        0      0        0     0  \n",
       "2     0        0      0        0     0  \n",
       "3     0        0      0        0     0  \n",
       "4     0        0      0        0     0  \n",
       "\n",
       "[5 rows x 312 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try changing a few parameters\n",
    "cv1 = CountVectorizer(binary=True, stop_words = 'english') #define the transformation\n",
    "cv1_dm = cv1.fit_transform(textStr) #apply the transformation\n",
    "\n",
    "#print(type(cv1_dm))\n",
    "print(cv1_dm.shape)\n",
    "countVectororizerTable = pd.DataFrame(cv1_dm.toarray(), columns = cv1.get_feature_names())\n",
    "countVectororizerTable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the second try I count total number of words (set binary to false), removed English stop words, used minimual document frequency of 1% to maximum document frequency of 50%. It returned 41 feature spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017</th>\n",
       "      <th>analysis</th>\n",
       "      <th>announce</th>\n",
       "      <th>api</th>\n",
       "      <th>available</th>\n",
       "      <th>collection</th>\n",
       "      <th>conference</th>\n",
       "      <th>cran</th>\n",
       "      <th>data</th>\n",
       "      <th>developed</th>\n",
       "      <th>...</th>\n",
       "      <th>start</th>\n",
       "      <th>statistical</th>\n",
       "      <th>talk</th>\n",
       "      <th>time</th>\n",
       "      <th>use</th>\n",
       "      <th>used</th>\n",
       "      <th>users</th>\n",
       "      <th>using</th>\n",
       "      <th>variable</th>\n",
       "      <th>written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2017  analysis  announce  api  available  collection  conference  cran  \\\n",
       "0     0         0         0    0          0           0           0     0   \n",
       "1     0         0         0    0          0           0           0     0   \n",
       "2     0         0         0    0          0           0           0     0   \n",
       "3     0         0         0    0          0           0           0     0   \n",
       "4     0         0         0    0          0           0           0     0   \n",
       "\n",
       "   data  developed   ...     start  statistical  talk  time  use  used  users  \\\n",
       "0     0          0   ...         0            0     1     0    2     0      0   \n",
       "1     0          0   ...         0            0     0     2    0     1      0   \n",
       "2     1          0   ...         1            0     0     0    0     0      0   \n",
       "3     0          0   ...         0            0     0     0    0     0      0   \n",
       "4     0          0   ...         0            0     0     0    0     0      0   \n",
       "\n",
       "   using  variable  written  \n",
       "0      0         0        0  \n",
       "1      0         0        0  \n",
       "2      1         0        0  \n",
       "3      0         0        0  \n",
       "4      0         0        0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2 = CountVectorizer(stop_words = 'english', min_df = .05, max_df =.5) #define the transformation\n",
    "cv2_dm = cv2.fit_transform(textStr) #apply the transformation\n",
    "\n",
    "#print(type(cv2_dm))\n",
    "print(cv2_dm.shape)\n",
    "countVectororizerTable = pd.DataFrame(cv2_dm.toarray(),columns = cv2.get_feature_names())\n",
    "countVectororizerTable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the third try counted total number of words (set binary to false), removed English stop words, used minimual document frequency of 10% to maximum document frequency of 50%, used ngram range of one to two words. It returned 46 feature spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017</th>\n",
       "      <th>analysis</th>\n",
       "      <th>announce</th>\n",
       "      <th>api</th>\n",
       "      <th>available</th>\n",
       "      <th>available cran</th>\n",
       "      <th>collection</th>\n",
       "      <th>conference</th>\n",
       "      <th>cran</th>\n",
       "      <th>data</th>\n",
       "      <th>...</th>\n",
       "      <th>statistical</th>\n",
       "      <th>statistical analysis</th>\n",
       "      <th>talk</th>\n",
       "      <th>time</th>\n",
       "      <th>use</th>\n",
       "      <th>used</th>\n",
       "      <th>users</th>\n",
       "      <th>using</th>\n",
       "      <th>variable</th>\n",
       "      <th>written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2017  analysis  announce  api  available  available cran  collection  \\\n",
       "0     0         0         0    0          0               0           0   \n",
       "1     0         0         0    0          0               0           0   \n",
       "2     0         0         0    0          0               0           0   \n",
       "3     0         0         0    0          0               0           0   \n",
       "4     0         0         0    0          0               0           0   \n",
       "\n",
       "   conference  cran  data   ...     statistical  statistical analysis  talk  \\\n",
       "0           0     0     0   ...               0                     0     1   \n",
       "1           0     0     0   ...               0                     0     0   \n",
       "2           0     0     1   ...               0                     0     0   \n",
       "3           0     0     0   ...               0                     0     0   \n",
       "4           0     0     0   ...               0                     0     0   \n",
       "\n",
       "   time  use  used  users  using  variable  written  \n",
       "0     0    2     0      0      0         0        0  \n",
       "1     2    0     1      0      0         0        0  \n",
       "2     0    0     0      0      1         0        0  \n",
       "3     0    0     0      0      0         0        0  \n",
       "4     0    0     0      0      0         0        0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv3 = CountVectorizer(min_df = .05, max_df =.5, stop_words = \"english\", ngram_range = (1,2)) #define the transformation\n",
    "cv3_dm = cv3.fit_transform(textStr) #apply the transformation\n",
    "#print(type(cv3_dm))\n",
    "print(cv3_dm.shape)\n",
    "\n",
    "countVectororizerTable = pd.DataFrame(cv3_dm.toarray(), columns = cv3.get_feature_names())\n",
    "countVectororizerTable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysis</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announce</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>api</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           total count\n",
       "2017                 2\n",
       "analysis             3\n",
       "announce             2\n",
       "api                  3\n",
       "available            2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = cv3.get_feature_names()   #create list of feature names\n",
    "#print(type(names), len(names))\n",
    "count = np.sum(cv3_dm.toarray(), axis = 0) # add up feature counts \n",
    "#print(type(count), count.shape)\n",
    "count2 = count.tolist()  # convert numpy array to list\n",
    "#print(len(count2))\n",
    "count_df = pd.DataFrame(count2, index = names, columns = ['total count']) # create a dataframe from the list\n",
    "count_df.head() # notice entries are alphabetical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>used</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>users</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>written</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          total count\n",
       "used                2\n",
       "users               2\n",
       "using               5\n",
       "variable            2\n",
       "written             2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Write a short description of what the vector space represents and how you can use it. Make sure your answer is no longer than three paragraphs, and should at minimum answer these questions:\n",
    "*\tHow do the parameter settings affect the size of the feature space?\n",
    "*\tWhat parameter settings might be “best” for the question you have in mind? \n",
    "Hint:  if you want to show numbers, a table would work well here.  \n",
    "Audience: technical – fellow data scientists or other technical staff.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question I have in mind is what are some popular topics on R-blogger.  I can use count vectorizer table for this.  I collected twenty-eight blog posts from R-blogger site.  The dataset contains five columns: category, author, date, link, excerpt.  The excerpt column contains excerpt text that I can create a vector space model.  Vector space model convert text documents into numeric model such as a sparse matrix.  The Sklearn Learn library vector space function allow me to transform blog posts to a sparse matrix of documents (rows) and features/words (columns).  \n",
    "\n",
    "The parameter settings affected the size of the feature space. \n",
    "A good setting is 0.1 for min document frequency and 0.5 for max document frequency, this removed words that is less than 10% of the documents or more than 50% of the documents.\n",
    "We don't want to distinguish lower case vs upper case of the same terms. Another good setting is ngram from one to two words.  This would give us two words term such as \"data science\" in addition to single word terms \"data\" and \"science\". Another good setting is remove English stop words such as \"a\", \"the\", \"to\", \"is\"...etc. min_df, max_df, stop_words, lowercase all would reduce number of feature space come back from countVectorizerTable function.  The n_gram (1,2) setting would increase number of feature space because it considers both single word and double word terms. In the first try it returned 312 feature spaces, the second try returned 41 feature spaces, the third try returned 47 feature spaces.\n",
    "###### Table 1. Run Results\n",
    "| Runs                                                                  |  Feature Spaces               |\n",
    "| --------------------------------------------------------------------- |:-----------------------------:|\n",
    "| binary=True, stop_words = 'english'                                   |    312                        |\n",
    "| stop_words = 'english', min_df = .05, max_df =.5                      |     41                        |  \n",
    "| min_df = .05, max_df =.5, stop_words = \"english\", ngram_range = (1,2) |     46                        |\n",
    "\n",
    "###### Table 2. Parameters Inputs\n",
    "| Parameters    | Value         |  Meaning                                                                  |\n",
    "| :------------:|:-------------:|:-------------------------------------------------------------------------:|\n",
    "| min_df        | 0.1           |  Ignore terms that have a document frequency less than 0.1                |\n",
    "| max_df        | 0.5           |  Ignore terms that have a document frequency more than 0.5                |\n",
    "| stop_words    | english       |  Remove english stop words                                                |\n",
    "| ngram_range   | (1,2)         |  Only allow 1 or 2 words terms                                            |\n",
    "| binary        | False         |  Default setting to return integer count of the terms instead of binary   |\n",
    "| lowercase     | True          |  Default setting to convert all characters to lower cases                 |\n",
    "| encoding      | UTF8          |  Default setting to UTF8 encoding for the text                            |\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**T3.** Repeat the above using the Tfidf vectorizer. Use a variety of parameter settings. Try at least 3 different versions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn documentation [TfidVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the first try I did not use tf_idf weight, did not normalize value, used english stop words and set maximum features to 20. It returned 20 feature spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>analysis</th>\n",
       "      <th>data</th>\n",
       "      <th>dplyr</th>\n",
       "      <th>know</th>\n",
       "      <th>large</th>\n",
       "      <th>learning</th>\n",
       "      <th>library</th>\n",
       "      <th>numfocus</th>\n",
       "      <th>package</th>\n",
       "      <th>packageversion</th>\n",
       "      <th>practical</th>\n",
       "      <th>recently</th>\n",
       "      <th>science</th>\n",
       "      <th>sparklyr</th>\n",
       "      <th>statistical</th>\n",
       "      <th>time</th>\n",
       "      <th>use</th>\n",
       "      <th>using</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    __  analysis  data  dplyr  know  large  learning  library  numfocus  \\\n",
       "0  0.0       0.0   1.0    0.0   1.0    0.0       0.0      0.0       0.0   \n",
       "1  0.0       0.0   0.0    0.0   0.0    1.0       0.0      0.0       0.0   \n",
       "2  0.0       0.0   0.0    0.0   0.0    0.0       0.0      0.0       0.0   \n",
       "3  0.0       0.0   2.0    0.0   0.0    1.0       0.0      0.0       0.0   \n",
       "4  0.0       0.0   0.0    0.0   0.0    0.0       0.0      0.0       0.0   \n",
       "\n",
       "   package  packageversion  practical  recently  science  sparklyr  \\\n",
       "0      0.0             0.0        0.0       0.0      0.0       0.0   \n",
       "1      0.0             0.0        0.0       0.0      0.0       0.0   \n",
       "2      2.0             0.0        0.0       0.0      0.0       0.0   \n",
       "3      0.0             0.0        0.0       0.0      2.0       0.0   \n",
       "4      0.0             0.0        0.0       0.0      0.0       0.0   \n",
       "\n",
       "   statistical  time  use  using  version  \n",
       "0          0.0   0.0  0.0    0.0      0.0  \n",
       "1          0.0   0.0  1.0    0.0      0.0  \n",
       "2          0.0   1.0  0.0    0.0      0.0  \n",
       "3          0.0   0.0  0.0    0.0      0.0  \n",
       "4          0.0   0.0  0.0    0.0      0.0  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How do the weights work here?\n",
    "tfidf1 = TfidfVectorizer(use_idf=False, norm=None, stop_words = \"english\", max_features = 20) #define the transformation\n",
    "tf1_dm = tfidf1.fit_transform(textStr) #apply the transformation\n",
    "print(tf1_dm.shape)\n",
    "tfidfVectororizerTable = pd.DataFrame(tf1_dm.toarray(),columns = tfidf1.get_feature_names())\n",
    "tfidfVectororizerTable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the second try I used tf_idf weight, did not normalize value, used english stop words and set maximum features to 20. It returned 20 feature spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>api</th>\n",
       "      <th>collection</th>\n",
       "      <th>conference</th>\n",
       "      <th>cran</th>\n",
       "      <th>data</th>\n",
       "      <th>dplyr</th>\n",
       "      <th>earl</th>\n",
       "      <th>idea</th>\n",
       "      <th>new</th>\n",
       "      <th>package</th>\n",
       "      <th>post</th>\n",
       "      <th>recently</th>\n",
       "      <th>regression</th>\n",
       "      <th>set</th>\n",
       "      <th>statistical</th>\n",
       "      <th>talk</th>\n",
       "      <th>time</th>\n",
       "      <th>use</th>\n",
       "      <th>using</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.842771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.268684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.151073</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.537367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.802346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.981001</td>\n",
       "      <td>2.287854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.962003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.757858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.842771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.268684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  api  collection  conference  cran      data  dplyr  earl  idea  \\\n",
       "0       0.0  0.0         0.0         0.0   0.0  0.000000    0.0   0.0   0.0   \n",
       "1       0.0  0.0         0.0         0.0   0.0  0.000000    0.0   0.0   0.0   \n",
       "2       0.0  0.0         0.0         0.0   0.0  1.802346    0.0   0.0   0.0   \n",
       "3       0.0  0.0         0.0         0.0   0.0  0.000000    0.0   0.0   0.0   \n",
       "4       0.0  0.0         0.0         0.0   0.0  0.000000    0.0   0.0   0.0   \n",
       "\n",
       "        new   package      post  recently  regression       set  statistical  \\\n",
       "0  0.000000  0.000000  4.842771       0.0    0.000000  0.000000          0.0   \n",
       "1  0.000000  0.000000  0.000000       0.0    0.000000  0.000000          0.0   \n",
       "2  2.981001  2.287854  0.000000       0.0    0.000000  5.962003          0.0   \n",
       "3  0.000000  0.000000  4.842771       0.0    3.268684  0.000000          0.0   \n",
       "4  0.000000  0.000000  0.000000       0.0    0.000000  0.000000          0.0   \n",
       "\n",
       "       talk      time       use     using  \n",
       "0  3.268684  0.000000  5.151073  0.000000  \n",
       "1  0.000000  6.537367  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  2.757858  \n",
       "3  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf2 = TfidfVectorizer(use_idf=True, norm=None, stop_words = \"english\", max_features = 20) #define the transformation\n",
    "tf2_dm = tfidf2.fit_transform(textStr) #apply the transformation\n",
    "print(tf2_dm.shape)\n",
    "tfidfVectororizerTable = pd.DataFrame(tf2_dm.toarray(),columns = tfidf2.get_feature_names())\n",
    "tfidfVectororizerTable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the third try I use tf_idf weight, did not normalize value, used english stop words, set min_df to 5%, set max_df to 50%, ngram 1 to 2. It returned 46 feature spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017</th>\n",
       "      <th>analysis</th>\n",
       "      <th>announce</th>\n",
       "      <th>api</th>\n",
       "      <th>available</th>\n",
       "      <th>available cran</th>\n",
       "      <th>collection</th>\n",
       "      <th>conference</th>\n",
       "      <th>cran</th>\n",
       "      <th>data</th>\n",
       "      <th>...</th>\n",
       "      <th>statistical</th>\n",
       "      <th>statistical analysis</th>\n",
       "      <th>talk</th>\n",
       "      <th>time</th>\n",
       "      <th>use</th>\n",
       "      <th>used</th>\n",
       "      <th>users</th>\n",
       "      <th>using</th>\n",
       "      <th>variable</th>\n",
       "      <th>written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.268684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.151073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.537367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.268684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.802346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.757858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2017  analysis  announce  api  available  available cran  collection  \\\n",
       "0   0.0       0.0       0.0  0.0        0.0             0.0         0.0   \n",
       "1   0.0       0.0       0.0  0.0        0.0             0.0         0.0   \n",
       "2   0.0       0.0       0.0  0.0        0.0             0.0         0.0   \n",
       "3   0.0       0.0       0.0  0.0        0.0             0.0         0.0   \n",
       "4   0.0       0.0       0.0  0.0        0.0             0.0         0.0   \n",
       "\n",
       "   conference  cran      data   ...     statistical  statistical analysis  \\\n",
       "0         0.0   0.0  0.000000   ...             0.0                   0.0   \n",
       "1         0.0   0.0  0.000000   ...             0.0                   0.0   \n",
       "2         0.0   0.0  1.802346   ...             0.0                   0.0   \n",
       "3         0.0   0.0  0.000000   ...             0.0                   0.0   \n",
       "4         0.0   0.0  0.000000   ...             0.0                   0.0   \n",
       "\n",
       "       talk      time       use      used  users     using  variable  written  \n",
       "0  3.268684  0.000000  5.151073  0.000000    0.0  0.000000       0.0      0.0  \n",
       "1  0.000000  6.537367  0.000000  3.268684    0.0  0.000000       0.0      0.0  \n",
       "2  0.000000  0.000000  0.000000  0.000000    0.0  2.757858       0.0      0.0  \n",
       "3  0.000000  0.000000  0.000000  0.000000    0.0  0.000000       0.0      0.0  \n",
       "4  0.000000  0.000000  0.000000  0.000000    0.0  0.000000       0.0      0.0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf3 = TfidfVectorizer(use_idf=True, norm=None, stop_words = \"english\", min_df = 0.05, max_df = 0.5, ngram_range = (1,2)) #define the transformation\n",
    "tf3_dm = tfidf3.fit_transform(textStr) #apply the transformation\n",
    "print(tf3_dm.shape)\n",
    "tfidfVectororizerTable = pd.DataFrame(tf3_dm.toarray(), columns = tfidf3.get_feature_names())\n",
    "tfidfVectororizerTable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** Write a short description of what the weights mean and how they might affect your analysis. Make sure your answer is no longer than two paragraphs, and should at minimum answer these questions:\n",
    "* Does using weights make sense for your question?  If so, why?  If not, why not?\n",
    "Audience: technical – fellow data scientists or other technical staff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document frequency df(j) shows the number of document containing word j. \n",
    "Inverse document frequency idf(j) reverses scale by applying logarithmically scale on it.  If word j is in many documents then it is less important, if word j appears in a few documents then it is unique and more important.\n",
    "\n",
    "$$idf(j) = log(\\frac{N}{df(j)})$$\n",
    "![idf](formula1.png \"idf\")\n",
    "\n",
    "Term frequency tf(j) of term j is the raw count of term j in the document. The term frequency inverse-document-frequency tf_idf weighting is calculated by multiply tf(j) and idf(j).\n",
    "\n",
    "$$tf\\_idf(j) = tf(j) ∗ idf(j)$$\n",
    "![tf_idf](formula2.png \"tf_idf\")\n",
    "\n",
    "Setting this function's flag \"use_idf\" to true returns tf_idf weighting.  The tf_idf weighting is used to compute a score for the term.  The bigger the score the more important the term's value of the documents.  \n",
    "From this math foruma we can see:\n",
    "* If a term only appears in one document for many times then the weight will be the highest.\n",
    "* If a term appears only a few times or the document appears in a lot of document then the weight will be lower.\n",
    "* If a term appears in all documents equally then the idf weight value would be zero.\n",
    "\n",
    "**In this case my question is which of these posts I can read on regression.**  Using tf_idf weight make sense because I want to find a good post focused on \"regression\" out of all other posts on the R-blogger site.  If \"regression\" is mentioned in one post but not others, then it should have the highest weight on the term \"regression\". Yes, the document's weight of the term \"regression\" is high at 6.53 on one post, therefore the \"Permutation Theory In Action\"  is the post I need to read to learn more about how to use regression in R compare to all other posts on the R-blogger site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the blog post I should read, and its tf_idf weight of the terms from the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Category</th>\n",
       "      <th>author</th>\n",
       "      <th>Date</th>\n",
       "      <th>link</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Permutation Theory In Action</td>\n",
       "      <td>Post</td>\n",
       "      <td>John Mount</td>\n",
       "      <td>September 2, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/permutation-theory-in-action/</td>\n",
       "      <td>While working on a large client project using Sparklyr and multinomial regression we recently ran into a problem: Apache Spark chooses the order o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Headline Category      author               Date  \\\n",
       "16  Permutation Theory In Action     Post  John Mount  September 2, 2017   \n",
       "\n",
       "                                                        link  \\\n",
       "16  https://www.r-bloggers.com/permutation-theory-in-action/   \n",
       "\n",
       "                                                                                                                                                  excerpt  \n",
       "16  While working on a large client project using Sparklyr and multinomial regression we recently ran into a problem: Apache Spark chooses the order o...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnndf.loc[[16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017                    0.000000\n",
      "analysis                0.000000\n",
      "announce                0.000000\n",
      "api                     0.000000\n",
      "available               0.000000\n",
      "available cran          0.000000\n",
      "collection              0.000000\n",
      "conference              0.000000\n",
      "cran                    0.000000\n",
      "data                    0.000000\n",
      "data science            0.000000\n",
      "developed               0.000000\n",
      "effective               0.000000\n",
      "excited                 0.000000\n",
      "excited announce        0.000000\n",
      "high                    0.000000\n",
      "idea                    0.000000\n",
      "interface               0.000000\n",
      "large                   3.268684\n",
      "learning                0.000000\n",
      "model                   0.000000\n",
      "new                     0.000000\n",
      "order                   3.268684\n",
      "package                 0.000000\n",
      "people                  0.000000\n",
      "post                    0.000000\n",
      "previous                0.000000\n",
      "previous post           0.000000\n",
      "process                 0.000000\n",
      "provides                0.000000\n",
      "reading                 0.000000\n",
      "recently                2.981001\n",
      "regression              6.537367\n",
      "science                 0.000000\n",
      "set                     0.000000\n",
      "start                   0.000000\n",
      "statistical             0.000000\n",
      "statistical analysis    0.000000\n",
      "talk                    0.000000\n",
      "time                    0.000000\n",
      "use                     0.000000\n",
      "used                    0.000000\n",
      "users                   0.000000\n",
      "using                   2.757858\n",
      "variable                0.000000\n",
      "written                 0.000000\n",
      "Name: 16, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(tfidfVectororizerTable.loc[16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** Besides emojis and encodings that we discussed in class, what other changes might you consider making to the text, if any?  What effect would you expect this to have? If you wouldn’t make any other changes, explain why not. \n",
    "Audience: general – management or non-technical staff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would consider do the following:\n",
    "* A lot of these blog posts have example code in it.  I would like to exclude the R language key words such as \"package\", \"library\", \"version\"...etc.  Remove them because the example code common keywords are not useful for understanding the question.\n",
    "* The term such as \"use\" and \"using\" can be grouped into the same column by perform Stemming. One feature/column for the term \"use\". \n",
    "* Excludes verbs such as \"need\", \"open\", \"open\", \"ran\".  These verbs do not help understand the question I try to ask. Remove them from the table.\n",
    "* Year 2017 is not the same as 2017 in total count. We need to distinguish them.\n",
    "* Remove comma from numbers.  For example, convert 1,000 to 1000. '000' should not be a separate token.\n",
    "* A run from last week showed special character \"-\" is separate out from \"2-D\" and \"3-D\".  It would treat \"2D\" and \"3D\" as a single token or remove \"-\" from \"2-D\" and \"3-D\".\n",
    "* For multiple words term like \"statistical analysis\" if single word term \"statistical\" and \"analysis\" also exist with the same frequency then we know multiple words term is all we need.   \n",
    "\n",
    "These will make the feature space terms more meaningful, and reduce the number of feature space terms that are too general.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
