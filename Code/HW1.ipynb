{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIA 6304 Text Mining, Fall 2017\n",
    "## Assignment 1\n",
    "### Stuent:  Leonardo Ji\n",
    "### 8/26/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**T1.** Create a data frame of news headlines similar to the example done in class.  The source can be any “reputable” news website.  Include the headline, the date, a category or classification, and one other descriptive term about the headline (e.g. short/long, opinion, includes video?, etc.) and show only the head and the tail of the data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd   #we almost always need pandas because we like data frames\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# R-Blogger news\n",
    "page = requests.get('https://www.r-bloggers.com')\n",
    "\n",
    "soup = BeautifulSoup(page.text, \"html5lib\")\n",
    "#print(type(soup))\n",
    "#print (soup.prettify)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BSobj = soup.find_all(\"div\",{\"class\":\"twopost\"})\n",
    "#print(type(BSobj))\n",
    "#print(len(BSobj))\n",
    "#print(BSobj)\n",
    "#BSobj[0]\n",
    "#BSobj[0].a[\"href\"]\n",
    "#BSobj[0].a.get_text()\n",
    "#BSobj[0].find(\"div\",{\"class\":\"date\"}).get_text()\n",
    "#BSobj[0].find(\"p\",{\"class\":\"excerpt\"}).get_text()\n",
    "#BSobj[0].find(\"a\",{\"rel\":\"author\"}).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headlines = {}\n",
    "for item in BSobj:\n",
    "    date = item.find(\"div\",{\"class\":\"date\"}).get_text()\n",
    "    link = item.a[\"href\"]\n",
    "    author = item.find(\"a\",{\"rel\":\"author\"}).get_text()\n",
    "    excerpt = item.find(\"p\",{\"class\":\"excerpt\"}).get_text().replace('\\n', '')\n",
    "    headlines[item.a.get_text()] = {}\n",
    "    headlines[item.a.get_text()][\"category\"] = \"Post\"\n",
    "    headlines[item.a.get_text()][\"author\"] = author\n",
    "    headlines[item.a.get_text()][\"date\"] = date\n",
    "    headlines[item.a.get_text()][\"link\"] = link\n",
    "    headlines[item.a.get_text()][\"excerpt\"] = excerpt\n",
    "    \n",
    "#print(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "cnndf = pd.DataFrame.from_dict(headlines,orient=\"index\")\n",
    "#print(cnndf.shape)\n",
    "cnndf.reset_index(inplace=True)\n",
    "\n",
    "cnndf.columns = ['Headline', 'Category', 'Author', 'Date', 'Link', 'Excerpt']\n",
    "print(len(cnndf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Category</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Link</th>\n",
       "      <th>Excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A simple function for installing R packages ba...</td>\n",
       "      <td>Post</td>\n",
       "      <td>R and Finance</td>\n",
       "      <td>August 24, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/a-simple-function-f...</td>\n",
       "      <td>-           Whenever I buy a new co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyzing Google Trends Data in R</td>\n",
       "      <td>Post</td>\n",
       "      <td>Jake Hoare</td>\n",
       "      <td>August 23, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/analyzing-google-tr...</td>\n",
       "      <td>Google Trends shows the changes in the popular...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BH 1.65.0-1</td>\n",
       "      <td>Post</td>\n",
       "      <td>Thinking inside the box</td>\n",
       "      <td>August 24, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/bh-1-65-0-1/</td>\n",
       "      <td>The BH package on CRAN was updated today to v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Big Data analytics with RevoScaleR Exercises</td>\n",
       "      <td>Post</td>\n",
       "      <td>Biswarup Ghosh</td>\n",
       "      <td>August 24, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/big-data-analytics-...</td>\n",
       "      <td>In this set of exercise , you will explore how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boston EARL Keynote speaker announcement: Tare...</td>\n",
       "      <td>Post</td>\n",
       "      <td>Mango Solutions</td>\n",
       "      <td>August 24, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/boston-earl-keynote...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline Category  \\\n",
       "0  A simple function for installing R packages ba...     Post   \n",
       "1                  Analyzing Google Trends Data in R     Post   \n",
       "2                                        BH 1.65.0-1     Post   \n",
       "3       Big Data analytics with RevoScaleR Exercises     Post   \n",
       "4  Boston EARL Keynote speaker announcement: Tare...     Post   \n",
       "\n",
       "                    Author             Date  \\\n",
       "0            R and Finance  August 24, 2017   \n",
       "1               Jake Hoare  August 23, 2017   \n",
       "2  Thinking inside the box  August 24, 2017   \n",
       "3           Biswarup Ghosh  August 24, 2017   \n",
       "4          Mango Solutions  August 24, 2017   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://www.r-bloggers.com/a-simple-function-f...   \n",
       "1  https://www.r-bloggers.com/analyzing-google-tr...   \n",
       "2            https://www.r-bloggers.com/bh-1-65-0-1/   \n",
       "3  https://www.r-bloggers.com/big-data-analytics-...   \n",
       "4  https://www.r-bloggers.com/boston-earl-keynote...   \n",
       "\n",
       "                                             Excerpt  \n",
       "0             -           Whenever I buy a new co...  \n",
       "1  Google Trends shows the changes in the popular...  \n",
       "2   The BH package on CRAN was updated today to v...  \n",
       "3  In this set of exercise , you will explore how...  \n",
       "4                                                ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Category</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Link</th>\n",
       "      <th>Excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Stan Weekly Roundup, 25 August 2017</td>\n",
       "      <td>Post</td>\n",
       "      <td>Bob Carpenter</td>\n",
       "      <td>August 25, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/stan-weekly-roundup...</td>\n",
       "      <td>This week, the entire Columbia portion of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Tidy evaluation, most common actions</td>\n",
       "      <td>Post</td>\n",
       "      <td>That’s so Random</td>\n",
       "      <td>August 25, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/tidy-evaluation-mos...</td>\n",
       "      <td>Tidy evaluation is a bit challenging to get yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Tips and tricks on using R to query data in Po...</td>\n",
       "      <td>Post</td>\n",
       "      <td>David Smith</td>\n",
       "      <td>August 25, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/tips-and-tricks-on-...</td>\n",
       "      <td>In Power BI, the dashboarding and reporting to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Unbottling “.msg” Files in R</td>\n",
       "      <td>Post</td>\n",
       "      <td>hrbrmstr</td>\n",
       "      <td>August 25, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/unbottling-msg-file...</td>\n",
       "      <td>There was a discussion on Twitter about the ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>wrapr: R Code Sweeteners</td>\n",
       "      <td>Post</td>\n",
       "      <td>John Mount</td>\n",
       "      <td>August 25, 2017</td>\n",
       "      <td>https://www.r-bloggers.com/wrapr-r-code-sweete...</td>\n",
       "      <td>wrapr is an R package that supplies powerful t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline Category  \\\n",
       "23                Stan Weekly Roundup, 25 August 2017     Post   \n",
       "24               Tidy evaluation, most common actions     Post   \n",
       "25  Tips and tricks on using R to query data in Po...     Post   \n",
       "26                       Unbottling “.msg” Files in R     Post   \n",
       "27                           wrapr: R Code Sweeteners     Post   \n",
       "\n",
       "              Author             Date  \\\n",
       "23     Bob Carpenter  August 25, 2017   \n",
       "24  That’s so Random  August 25, 2017   \n",
       "25       David Smith  August 25, 2017   \n",
       "26          hrbrmstr  August 25, 2017   \n",
       "27        John Mount  August 25, 2017   \n",
       "\n",
       "                                                 Link  \\\n",
       "23  https://www.r-bloggers.com/stan-weekly-roundup...   \n",
       "24  https://www.r-bloggers.com/tidy-evaluation-mos...   \n",
       "25  https://www.r-bloggers.com/tips-and-tricks-on-...   \n",
       "26  https://www.r-bloggers.com/unbottling-msg-file...   \n",
       "27  https://www.r-bloggers.com/wrapr-r-code-sweete...   \n",
       "\n",
       "                                              Excerpt  \n",
       "23  This week, the entire Columbia portion of the ...  \n",
       "24  Tidy evaluation is a bit challenging to get yo...  \n",
       "25  In Power BI, the dashboarding and reporting to...  \n",
       "26  There was a discussion on Twitter about the ne...  \n",
       "27  wrapr is an R package that supplies powerful t...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnndf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** Write a short description of what the data you have captured are and how they might be used. Make sure your answer is no longer than two paragraphs, and should at minimum answer these questions:\n",
    "* What information can we get from the text in this data frame?\n",
    "* Why do the category assignment? What is the other term you chose?  Why?\n",
    "* How do you think we will be able to use this?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case I captured data from the R-blogger website (https://www.r-bloggers.com/). The R-blogger has blob articles on the R language. There are total of twenty-eight blog posts on 8/26/2017 8:06pm. **The captured information includes six categories of text: headline, category, author, date, link, and excerpt**. The headline is the blog post title, category is type of the post, author is the author of the post, date is date of post, link is the actual link of the post, and except is except of the post. **These six categories give me a basic outline of each post and uniquely identify what the post is about**. News Website are in HTML5 format. Website HTML format is machine readable but very hard to read by a human. And there are huge volume of text on the internet and constantly updated with newer information. It is impossible to read all of them. Web scraping allows automatically capture text from website and convert it to a spreadsheet table by inserting the same category of text into a table column. This table can be transformed to a numerical format. \n",
    "**Depends on the questions we want to ask we can apply the same data mining techniques on category of text for classification or predictions. For example, we can measure similarity by count number of same words in each category columns**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**T2.** Create a new data frame of twitter information. Choose a search term and fetch 500 tweets. Modify your function to include only the fields you think are necessary and create a data frame. Don’t forget to show only the head and tail of that data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consumer_key = 'dED7sjmSHUTDCDUVqukfmHcQx'\n",
    "consumer_secret = '5Tmd0FpumkpHPMClkcvjpQdrF9aWCB5QOOnzmUR3UZQNJu4zcj'\n",
    "access_token = '900008085099614208-N450kfbZMV0HFWjiRQqxfek0U4qWLGU'\n",
    "access_secret = 'j3VzolJ74yUuLl4Bc8LhNudmfwy0gonO3A4UOGs63XasE'\n",
    "\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# A SearchResults object isn't very helpful, how about a list\n",
    "results = []\n",
    "\n",
    "#Get the first 500 items based on the search query\n",
    "for tweet in tweepy.Cursor(api.search, q='#datascience').items(500):\n",
    "    results.append(tweet)\n",
    "\n",
    "# Verify the number of items returned\n",
    "print(type(results))\n",
    "print(len(results))\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toDataFrame(tweets):\n",
    "\n",
    "    DataSet = pd.DataFrame()\n",
    "\n",
    "    DataSet['tweetText'] = [tweet.text for tweet in tweets]\n",
    "    DataSet['tweetRetweetCt'] = [tweet.retweet_count for tweet \n",
    "    in tweets]\n",
    "    DataSet['tweetCreated'] = [tweet.created_at for tweet in tweets]\n",
    "    DataSet['userLocation'] = [tweet.user.location for tweet in tweets]\n",
    "    DataSet['hashtag'] = [tweet.entities for tweet in tweets]\n",
    "    return DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 5)\n"
     ]
    }
   ],
   "source": [
    "#let's use the function with our list\n",
    "#Pass the tweets list to the above function to create a DataFrame\n",
    "tweet_frame = toDataFrame(results)\n",
    "# sort by retweet count\n",
    "tweet_frame = tweet_frame.sort_values(by='tweetRetweetCt', ascending=0)\n",
    "print(tweet_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetText</th>\n",
       "      <th>tweetRetweetCt</th>\n",
       "      <th>tweetCreated</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>RT @eLearning_Feed: Big Data Analysis Course O...</td>\n",
       "      <td>264</td>\n",
       "      <td>2017-09-04 00:29:31</td>\n",
       "      <td>Aix-en-Provence, France</td>\n",
       "      <td>{'hashtags': [{'text': 'bigdata', 'indices': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>RT @ipfconline1: 100 Most Popular #Programming...</td>\n",
       "      <td>224</td>\n",
       "      <td>2017-09-04 01:28:04</td>\n",
       "      <td>Hyderabad, Telangana</td>\n",
       "      <td>{'hashtags': [{'text': 'Programming', 'indices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>RT @evankirstel: How big is #BigData at big co...</td>\n",
       "      <td>210</td>\n",
       "      <td>2017-09-04 01:02:59</td>\n",
       "      <td>Bogotá, D.C., Colombia</td>\n",
       "      <td>{'hashtags': [{'text': 'BigData', 'indices': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>RT @evankirstel: How big is #BigData at big co...</td>\n",
       "      <td>210</td>\n",
       "      <td>2017-09-04 00:36:16</td>\n",
       "      <td>Nantes Vannes Paris</td>\n",
       "      <td>{'hashtags': [{'text': 'BigData', 'indices': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RT @Info_Data_Mgmt: Who's driving #AI? \\n\\n#Da...</td>\n",
       "      <td>176</td>\n",
       "      <td>2017-09-04 02:13:39</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>{'hashtags': [{'text': 'AI', 'indices': [34, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweetText  tweetRetweetCt  \\\n",
       "475  RT @eLearning_Feed: Big Data Analysis Course O...             264   \n",
       "210  RT @ipfconline1: 100 Most Popular #Programming...             224   \n",
       "338  RT @evankirstel: How big is #BigData at big co...             210   \n",
       "451  RT @evankirstel: How big is #BigData at big co...             210   \n",
       "11   RT @Info_Data_Mgmt: Who's driving #AI? \\n\\n#Da...             176   \n",
       "\n",
       "           tweetCreated             userLocation  \\\n",
       "475 2017-09-04 00:29:31  Aix-en-Provence, France   \n",
       "210 2017-09-04 01:28:04     Hyderabad, Telangana   \n",
       "338 2017-09-04 01:02:59   Bogotá, D.C., Colombia   \n",
       "451 2017-09-04 00:36:16      Nantes Vannes Paris   \n",
       "11  2017-09-04 02:13:39            Manhattan, NY   \n",
       "\n",
       "                                               hashtag  \n",
       "475  {'hashtags': [{'text': 'bigdata', 'indices': [...  \n",
       "210  {'hashtags': [{'text': 'Programming', 'indices...  \n",
       "338  {'hashtags': [{'text': 'BigData', 'indices': [...  \n",
       "451  {'hashtags': [{'text': 'BigData', 'indices': [...  \n",
       "11   {'hashtags': [{'text': 'AI', 'indices': [34, 3...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "try:\n",
    "    # UCS-4\n",
    "    highpoints = re.compile(u'([\\U00002600-\\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF])')\n",
    "except re.error:\n",
    "    # UCS-2\n",
    "    highpoints = re.compile(u'([\\u2600-\\u27BF])|([\\uD83C][\\uDF00-\\uDFFF])|([\\uD83D][\\uDC00-\\uDE4F])|([\\uD83D][\\uDE80-\\uDEFF])')\n",
    "highpoints\n",
    "\n",
    "# to decode unicode to ascii in a dataframe column\n",
    "tweet_frame['tweetText'] = list(map(lambda x: highpoints.sub(u'',x), tweet_frame['tweetText']))\n",
    "\n",
    "tweet_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetText</th>\n",
       "      <th>tweetRetweetCt</th>\n",
       "      <th>tweetCreated</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Introduction to R Data Visualization. #SQLServ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-04 01:45:14</td>\n",
       "      <td>USA</td>\n",
       "      <td>{'hashtags': [{'text': 'SQLServer', 'indices':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>8 ways you can grow your business using #DataS...</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-04 01:46:03</td>\n",
       "      <td>Ahmadabad City, Gujarat</td>\n",
       "      <td>{'hashtags': [{'text': 'DataScience', 'indices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>Information Security: Take responsibility if y...</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-04 00:32:03</td>\n",
       "      <td>Parkville, MD</td>\n",
       "      <td>{'hashtags': [{'text': 'technews', 'indices': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Computer Age Statistical Inference: Algorithms...</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-04 00:32:00</td>\n",
       "      <td></td>\n",
       "      <td>{'hashtags': [{'text': 'DataScience', 'indices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>#MachineLearning in #fintech Demystified https...</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-04 01:33:26</td>\n",
       "      <td>In XLSX Files</td>\n",
       "      <td>{'hashtags': [{'text': 'MachineLearning', 'ind...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweetText  tweetRetweetCt  \\\n",
       "130  Introduction to R Data Visualization. #SQLServ...               0   \n",
       "125  8 ways you can grow your business using #DataS...               0   \n",
       "460  Information Security: Take responsibility if y...               0   \n",
       "461  Computer Age Statistical Inference: Algorithms...               0   \n",
       "182  #MachineLearning in #fintech Demystified https...               0   \n",
       "\n",
       "           tweetCreated             userLocation  \\\n",
       "130 2017-09-04 01:45:14                      USA   \n",
       "125 2017-09-04 01:46:03  Ahmadabad City, Gujarat   \n",
       "460 2017-09-04 00:32:03            Parkville, MD   \n",
       "461 2017-09-04 00:32:00                            \n",
       "182 2017-09-04 01:33:26            In XLSX Files   \n",
       "\n",
       "                                               hashtag  \n",
       "130  {'hashtags': [{'text': 'SQLServer', 'indices':...  \n",
       "125  {'hashtags': [{'text': 'DataScience', 'indices...  \n",
       "460  {'hashtags': [{'text': 'technews', 'indices': ...  \n",
       "461  {'hashtags': [{'text': 'DataScience', 'indices...  \n",
       "182  {'hashtags': [{'text': 'MachineLearning', 'ind...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_frame.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Write a short description of what the data you have captured are and how they might be used. Make sure your answer is no longer than two paragraphs, and should at minimum answer these questions:\n",
    "* What is interesting about the term you chose? What do you want to know about it?\n",
    "* What fields do you think are necessary for your question? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I captured five hundred of tweets on Twitter hashtag Data Science. **I want to learn what are people discussing about Data Science on Twitter in each country. What are the trending or popular topics on Data Science now, and what other hashtags (related topics) twitter user used with Data Science**. This gives me other Data Science related topics, for example Big Data, Machine Learning, AI, Python…etc. If I count them I know that is the most popular related topics in Data Science I want to learn. From each tweet, **I picked five attributes necessary to answer the above question: text, retweet count, tweet create date time, user location, hashtags**. The results are sorted by retweet counts in descending order. After sorting the table shows the most popular data science topic on Twitter now. The emoji are removed from te the tweet. The created date time column shows what is the time of the tweet, the user location column shows where is the users' location countries. The hashtags column shows all other related hashtags topics also on the tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** Write a short description comparing these two data sources. Make sure your answer is no longer than 3 paragraphs, and should at minimum answer these questions:\n",
    "* How technically different was the collection and manipulation of these two data sources?  How much of a consideration is that (or should that be) when considering what data to use for answering a question?\n",
    "* How would you evaluate which data source to use from a context or relevance perspective?  Is all web or social media content equally valuable/useful/relevant?  Why or why not? How do you decide which data should be used to answer what question?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They both pull data from the Internet into a table of attributes. Each data point is a row on this table.  Each attribute is a column. The first question's data source is collected by web scrapping text data from news website. **The web scrapping method searches for a specific story from the website and save attributes, there can be a very large number of attributes depends on the website. The second question's data source is pulling data from twitter by hashtag topic.** For example, we search for a specific hashtag “Data Science” on twitter, and limit results to five hundred results. Each tweet has a fixed number of attributes and we select five attributes from them to answer a question. The twitter data source is constantly updating and each time it gives us a different result. Tweets are usually in 140 characters or less and the news website article typically contains a much larger text.\n",
    "\n",
    "**Selecting a data source depends on the problems we want to solve**. If we want to most update-to-date information, for example doing sentimental analysis on a product then we need to use Twitter data. The social media content like twitter is more relevant if we want to study the effects now, for example presidential debates, product launch, natural disasters…etc. Twitter allows us to see instant changes. \n",
    "\n",
    "**No web or social media content are not equally valuable, useful, or relevant.  Web resource contains more data.  Social media sites have the latest updates from users.**  If we want to use a large text data for similarity comparisons or predictions, then we need to use web resource. The website data does not update by seconds like Twitter but it contains larger text data than twitter data.  Depends on the question we want to ask and what is more important (more recent update vs. larger text) we would pick a data source and its attributes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
